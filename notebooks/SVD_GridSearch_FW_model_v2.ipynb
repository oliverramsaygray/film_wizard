{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "241180aa",
   "metadata": {},
   "source": [
    "## Final version - simplified SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44eb6df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "print(\"Authenticated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53a16182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverramsaygray/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1900: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from BigQuery: (1000000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29022</td>\n",
       "      <td>6548</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38843</td>\n",
       "      <td>260</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3035</td>\n",
       "      <td>8678</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195624</td>\n",
       "      <td>5459</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87064</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0   29022     6548     4.0\n",
       "1   38843      260     4.0\n",
       "2    3035     8678     4.0\n",
       "3  195624     5459     1.5\n",
       "4   87064       36     4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from surprise.accuracy import rmse\n",
    "import pandas as pd\n",
    "\n",
    "# Define BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Define batch size & dataset properties\n",
    "BATCH_SIZE = 1_000_000  # 100k rows per batch\n",
    "TOTAL_ROWS = 32_000_000  # Approximate total dataset size\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "\n",
    "### **GL df**\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `film-wizard-453315.Grouplens.raw_grouplens_ratings`\n",
    "ORDER BY RAND()\n",
    "LIMIT 1000000\n",
    "\"\"\"\n",
    "\n",
    "# Fetch data from BigQuery\n",
    "gl_df = client.query(sample_query).to_dataframe()\n",
    "print(\"Loaded data from BigQuery:\", gl_df.shape)\n",
    "display(gl_df.head(5))\n",
    "\n",
    "data = Dataset.load_from_df(gl_df, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6841726",
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_df['userId'].max()+1\n",
    "\n",
    "new_user_ratings = pd.read_csv('/Users/oliverramsaygray/code/oliverramsaygray/film_wizard/raw_data/letterboxd-oliverramsay-2025-03-13-15-05-utc/new_user_ratings.csv')\n",
    "new_user_ratings = new_user_ratings[new_user_ratings['Year'] <= 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac9d89f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ratings.drop(columns=['Date', 'Year', 'Letterboxd URI'], inplace=True)\n",
    "new_user_ratings.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f41a872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Three Billboards Outside Ebbing, Missouri</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nomadland</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lady Bird</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yesterday</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coco</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mid90s</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Street</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>There Will Be Blood</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pain and Glory</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senna</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fences</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Don't Look Up</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Name  Rating\n",
       "0   Three Billboards Outside Ebbing, Missouri     4.5\n",
       "1                                   Nomadland     4.0\n",
       "2                                   Lady Bird     3.0\n",
       "3                                   Yesterday     2.5\n",
       "4                                        Coco     3.5\n",
       "5                                      mid90s     4.0\n",
       "6                                  The Street     4.0\n",
       "7                         There Will Be Blood     3.5\n",
       "8                              Pain and Glory     3.0\n",
       "9                                       Senna     3.5\n",
       "10                                     Fences     4.0\n",
       "11                              Don't Look Up     3.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ebd88e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverramsaygray/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1900: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from BigQuery: (1000000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181685</td>\n",
       "      <td>به نام پدر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139596</td>\n",
       "      <td>Danielův svět</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151307</td>\n",
       "      <td>The Lovers and the Despot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>178223</td>\n",
       "      <td>Injecting Aluminum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189345</td>\n",
       "      <td>The Doctor From India</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                      title\n",
       "0   181685                 به نام پدر\n",
       "1   139596              Danielův svět\n",
       "2   151307  The Lovers and the Despot\n",
       "3   178223         Injecting Aluminum\n",
       "4   189345      The Doctor From India"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Fuzzy matching ###\n",
    "### **GL df**\n",
    "sample_query = \"\"\"\n",
    "SELECT movieId, title\n",
    "FROM `film-wizard-453315.Grouplens.grouplens_movies`\n",
    "\"\"\"\n",
    "\n",
    "# Fetch data from BigQuery\n",
    "grouplens_movies = client.query(sample_query).to_dataframe()\n",
    "print(\"Loaded data from BigQuery:\", gl_df.shape)\n",
    "display(grouplens_movies.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3db7738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "import pandas as pd\n",
    "\n",
    "def fuzzy_match(df1, col1, df2, col2, threshold=80):\n",
    "    matched_data = []\n",
    "    choices = df2[col2].tolist()  # Convert column to a list to avoid unpacking issues\n",
    "\n",
    "    for name in df1[col1]:\n",
    "        result = process.extractOne(name, choices, scorer=fuzz.ratio)\n",
    "        match, score = result if result else (\"\", 0)  # Ensure safe unpacking\n",
    "        matched_data.append((name, match if score >= threshold else None, score))\n",
    "\n",
    "    return pd.DataFrame(matched_data, columns=[col1, 'Matched_Title', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1d23058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matched_Title</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Three Billboards Outside Ebbing, Missouri</td>\n",
       "      <td>Three Billboards Outside Ebbing, Missouri</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nomadland</td>\n",
       "      <td>Nomadland</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lady Bird</td>\n",
       "      <td>Lady Bird</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yesterday</td>\n",
       "      <td>Yesterday</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coco</td>\n",
       "      <td>Coco</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mid90s</td>\n",
       "      <td>Mid90s</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Street</td>\n",
       "      <td>The Street</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>There Will Be Blood</td>\n",
       "      <td>There Will Be Blood</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pain and Glory</td>\n",
       "      <td>Pain and Glory</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senna</td>\n",
       "      <td>Senna</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fences</td>\n",
       "      <td>Fences</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Don't Look Up</td>\n",
       "      <td>Don't Look Up</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Name  \\\n",
       "0   Three Billboards Outside Ebbing, Missouri   \n",
       "1                                   Nomadland   \n",
       "2                                   Lady Bird   \n",
       "3                                   Yesterday   \n",
       "4                                        Coco   \n",
       "5                                      mid90s   \n",
       "6                                  The Street   \n",
       "7                         There Will Be Blood   \n",
       "8                              Pain and Glory   \n",
       "9                                       Senna   \n",
       "10                                     Fences   \n",
       "11                              Don't Look Up   \n",
       "\n",
       "                                Matched_Title  Score  \n",
       "0   Three Billboards Outside Ebbing, Missouri    100  \n",
       "1                                   Nomadland    100  \n",
       "2                                   Lady Bird    100  \n",
       "3                                   Yesterday    100  \n",
       "4                                        Coco    100  \n",
       "5                                      Mid90s    100  \n",
       "6                                  The Street    100  \n",
       "7                         There Will Be Blood    100  \n",
       "8                              Pain and Glory    100  \n",
       "9                                       Senna    100  \n",
       "10                                     Fences    100  \n",
       "11                              Don't Look Up    100  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "matches_df = fuzzy_match(new_user_ratings, 'Name', grouplens_movies, 'title')\n",
    "display(matches_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1b2be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and test set\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Create the SVD model and train it\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Define a function to get top 5 recommendations for a user\n",
    "def get_top_n(predictions, n):\n",
    "    top_n = {}\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid not in top_n:\n",
    "            top_n[uid] = []\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Sort the predictions for each user and return the top n\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    \n",
    "    return top_n\n",
    "\n",
    "# Load your data from BigQuery (assuming you have already loaded gl_df)\n",
    "# Here's an example:\n",
    "# gl_df = pd.read_csv('your_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0dc4529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9203  0.9204  0.9196  0.9200  0.9184  0.9197  0.0007  \n",
      "MAE (testset)     0.7069  0.7075  0.7060  0.7063  0.7062  0.7066  0.0005  \n",
      "Fit time          10.16   10.31   10.79   10.54   10.75   10.51   0.25    \n",
      "Test time         1.15    1.88    1.88    1.81    1.83    1.71    0.28    \n",
      "{'test_rmse': array([0.92025165, 0.92044244, 0.91963211, 0.91995995, 0.91844325]), 'test_mae': array([0.70689903, 0.70745444, 0.70601073, 0.70631366, 0.70616308]), 'fit_time': (10.158315181732178, 10.31357216835022, 10.790318012237549, 10.543659925460815, 10.752399921417236), 'test_time': (1.1525812149047852, 1.8755269050598145, 1.88232421875, 1.8144030570983887, 1.825963020324707)}\n"
     ]
    }
   ],
   "source": [
    "# **2️⃣ Cross-Validation Before Batch Training**\n",
    "cv_results = cross_validate(model, data, cv=5, verbose=True)\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1685ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1193, 4.204463778449138), (858, 4.125093975694352)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions for the testset\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Get the top 10 recommendations for each user\n",
    "top_n = get_top_n(predictions, n=10)\n",
    "top_n.get(11157)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92e9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2005778",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\n",
    "    132721: [(3030, 4.343930472863401),\n",
    "  (3147, 4.173104100455896),\n",
    "  (8014, 4.10402787200236)],\n",
    " 134273: [(69481, 3.2115050041528552),\n",
    "  (2917, 3.147696080876573),\n",
    "  (1227, 3.14304677816368)],\n",
    " 163615: [(1196, 4.082660659362825),\n",
    "  (7099, 4.038083503624332),\n",
    "  (608, 3.769995671477647)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fffb20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert user recommendations into a single DataFrame\n",
    "data = []\n",
    "for user_id, movies in top_n.items():\n",
    "    for movie_id, rating in movies:\n",
    "        data.append((user_id, movie_id, rating))\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"userId\", \"movieId\", \"rating\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f99840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each movieId\n",
    "movie_counts = df['movieId'].value_counts()\n",
    "\n",
    "# Filter rows where movieId appears more than once\n",
    "duplicated_movies_df = df[df['movieId'].isin(movie_counts[movie_counts > 1].index)]\n",
    "\n",
    "print(duplicated_movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d44dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['movieId'] == 55820]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dbeddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {\n",
    "    'userId': [132721],\n",
    "    'movieId': [3030],\n",
    "    'rating': [4.343930472863401]\n",
    "}\n",
    "\n",
    "test_df = pd.DataFrame(data=test_dict)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8634703e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b785d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store DataFrames\n",
    "user_dfs = {}\n",
    "\n",
    "# Loop through each userId and create a DataFrame\n",
    "for user_id in top_n:\n",
    "    movie_data = top_n[user_id]  # Get movie list for the user\n",
    "    movie_ids = []\n",
    "    predicted_ratings = []\n",
    "    \n",
    "    # Extract movieId and predicted_rating\n",
    "    for movie in movie_data:\n",
    "        movie_ids.append(movie[0])\n",
    "        predicted_ratings.append(movie[1])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\"movieId\": movie_ids, \"predicted_rating\": predicted_ratings})\n",
    "    \n",
    "    # Store in dictionary\n",
    "    user_dfs[user_id] = df\n",
    "\n",
    "# Display example output\n",
    "for user_id in user_dfs:\n",
    "    print(f\"User {user_id} recommendations:\")\n",
    "    print(user_dfs[user_id], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2b61ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a94537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af89d170",
   "metadata": {},
   "source": [
    "## SVD Grid Search User Review Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e0aa9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:10:16.772302Z",
     "start_time": "2025-03-13T11:10:16.721040Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "print(\"Authenticated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd541f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    }
   },
   "outputs": [],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate, GridSearchCV\n",
    "from surprise.accuracy import rmse\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Define BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Define batch size & dataset properties\n",
    "BATCH_SIZE = 100_000  # 100k rows per batch\n",
    "TOTAL_ROWS = 500_000  # Approximate total dataset size\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "\n",
    "### **GL df with  500k randomly sampled ratings**\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `film-wizard-453315.Grouplens.500k_ratings`\n",
    "ORDER BY RAND()\n",
    "\"\"\"\n",
    "sample_gl_df = client.query(sample_query).to_dataframe()\n",
    "sample_gl_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(sample_gl_df, reader)\n",
    "\n",
    "# Split the data into a training and test set\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Create the SVD model and train it\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Define a function to get top 5 recommendations for a user\n",
    "def get_top_n(predictions, n):\n",
    "    top_n = {}\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid not in top_n:\n",
    "            top_n[uid] = []\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Sort the predictions for each user and return the top n\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    \n",
    "    return top_n\n",
    "\n",
    "# **2️⃣ Cross-Validation Before Batch Training**\n",
    "cv_results = cross_validate(model, data, cv=5, verbose=True)\n",
    "print(cv_results)\n",
    "\n",
    "# Get predictions for the testset\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Get the top 5 recommendations for each user\n",
    "top_n = get_top_n(predictions, n=50)\n",
    "top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d64acb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "grouped_rating_df = sample_gl_df.groupby(by='movieId').count().sort_values(by='movieId', ascending=True)\n",
    "display(grouped_rating_df)\n",
    "\n",
    "# sns.histplot(data=grouped_rating_df, x='movieId')\n",
    "\n",
    "# sample_gl_df['quartile'] = pd.qcut(sample_gl_df['rating'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "# sample_gl_df\n",
    "\n",
    "# sample_gl_df.groupby(by='quartile').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd64cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = sample_gl_df.groupby('movieId').count().reset_index(names='num_reviews')\n",
    "grouped_df\n",
    "\n",
    "# grouped_df['quartile'] = pd.qcut(grouped_df['num_reviews'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "# group_df['quartile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b3620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    }
   },
   "outputs": [],
   "source": [
    "### **1️⃣ Perform Grid Search on Small Sample**\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `film-wizard-453315.Grouplens.500k_ratings`\n",
    "ORDER BY RAND()\n",
    "LIMIT 100000  -- Adjust for ~20% of 500k rows\n",
    "\"\"\"\n",
    "grid_search_df = client.query(sample_query).to_dataframe()\n",
    "data = Dataset.load_from_df(grid_search_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    \"n_factors\": [10, 20, 50],  \n",
    "    \"reg_all\": [0.01, 0.03, 0.05]  \n",
    "}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\"], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "best_params = gs.best_params[\"rmse\"]\n",
    "print(\"Best Params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb2c819",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    }
   },
   "outputs": [],
   "source": [
    "# **2️⃣ Cross-Validation Before Batch Training**\n",
    "best_algo = SVD(n_factors=best_params[\"n_factors\"], reg_all=best_params[\"reg_all\"])\n",
    "cv_results = cross_validate(best_algo, data, cv=5, verbose=True)\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8ff79f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    }
   },
   "outputs": [],
   "source": [
    "# **3️⃣ Train on Full Dataset in Batches**\n",
    "for offset in range(0, TOTAL_ROWS, BATCH_SIZE):\n",
    "    batch_query = f\"\"\"\n",
    "    SELECT userId, movieId, rating\n",
    "    FROM `film-wizard-453315.Grouplens.500k_ratings`\n",
    "    ORDER BY userId\n",
    "    LIMIT {BATCH_SIZE} OFFSET {offset}\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_df = client.query(batch_query).to_dataframe()\n",
    "    \n",
    "    if batch_df.empty:\n",
    "        break  # Stop when there are no more rows\n",
    "    \n",
    "    dataset = Dataset.load_from_df(batch_df[['userId', 'movieId', 'rating']], reader)\n",
    "    trainset = dataset.build_full_trainset()\n",
    "    \n",
    "    best_algo.fit(trainset)\n",
    "    print(f\"✅ Processed {offset + BATCH_SIZE} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d47138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    }
   },
   "outputs": [],
   "source": [
    "### **4️⃣ Evaluate Best Model on a Fresh Test Set**\n",
    "test_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `film-wizard-453315.Grouplens.500k_ratings`\n",
    "ORDER BY RAND()\n",
    "LIMIT 1500000  -- Adjust for ~5% of 32M rows\n",
    "\"\"\"\n",
    "test_df = client.query(test_query).to_dataframe()\n",
    "testset = Dataset.load_from_df(test_df[['userId', 'movieId', 'rating']], reader).build_full_trainset().build_testset()\n",
    "\n",
    "predictions = best_algo.test(testset)\n",
    "print(\"Final RMSE on test set:\", rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221fa27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieId_list = sample_gl_df['movieId']\n",
    "\n",
    "predictions_list = []\n",
    "\n",
    "for x in movieId_list:\n",
    "    predictions = best_algo.predict(2000, x)\n",
    "    predictions_list.append(predictions)\n",
    "    \n",
    "predictions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f88ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract movie IDs (iid) and predicted ratings (est)\n",
    "movie_ids = [pred.iid for pred in predictions_list]\n",
    "est_values = [pred.est for pred in predictions_list]\n",
    "\n",
    "# Plot the predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(movie_ids, est_values, alpha=0.5)\n",
    "plt.xlabel(\"Movie ID\")\n",
    "plt.ylabel(\"Predicted Rating (est)\")\n",
    "plt.title(\"Predicted Ratings for Each Movie\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b179c1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Lenskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f710a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from lenskit import crossfold\n",
    "from lenskit.als import BiasedMFScorer # https://lkpy.lenskit.org/stable/guide/gettingstarted\n",
    "from lenskit import util\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "print(\"Authenticated successfully!\")\n",
    "\n",
    "# Define batch size & dataset properties\n",
    "BATCH_SIZE = 100_000  # 100k rows per batch\n",
    "TOTAL_ROWS = 500_000  # Approximate total dataset size\n",
    "\n",
    "# Fetch 500k ratings from BigQuery randomly (for the entire dataset)\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM film-wizard-453315.Grouplens.500k_ratings\n",
    "ORDER BY RAND()\n",
    "\"\"\"\n",
    "sample_gl_df = client.query(sample_query).to_dataframe()\n",
    "\n",
    "# Rename columns to match LensKit's expected column names\n",
    "sample_gl_df = sample_gl_df.rename(columns={'userId': 'user_id', 'movieId': 'item_id'})\n",
    "sample_gl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf2491e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# I ned to define cv, hyperparam grid and then do a gridsearch\n",
    "\n",
    "# Train the model\n",
    "model = als.BiasedMF(features=3, reg=0.01, rng_spec=42)\n",
    "\n",
    "# Fit the model with your data\n",
    "model.fit(sample_gl_df[['user_id', 'item_id', 'rating']])\n",
    "\n",
    "# Create a scorer from the model\n",
    "scorer = model.scorer()\n",
    "\n",
    "# # ---------------------------\n",
    "\n",
    "# # Prepare data for training\n",
    "# train_data = sample_gl_df[['user', 'item', 'rating']]\n",
    "\n",
    "# # Define cross-validation with LensKit\n",
    "# folds = crossfold.sample_users(train_data, 5, size=0.2, method='random')  # 5-fold cross-validation\n",
    "\n",
    "# # Define a function for ALS model training\n",
    "# def train_als_model(train_data, factors=10, reg=0.01):\n",
    "#     algo = als.ALS(factors=factors, reg=reg, random_state=42)\n",
    "#     algo.fit(train_data)\n",
    "#     return algo\n",
    "\n",
    "# # Example hyperparameter grid (number of factors and regularization)\n",
    "# param_grid = {\n",
    "#     \"factors\": [5, 10, 50],\n",
    "#     \"reg\": [0.001, 0.01, 0.05]\n",
    "# }\n",
    "\n",
    "# # Manually grid search\n",
    "# best_rmse = float('inf')\n",
    "# best_params = {}\n",
    "\n",
    "# for factors in param_grid[\"factors\"]:\n",
    "#     for reg in param_grid[\"reg\"]:\n",
    "#         fold_rmse = []\n",
    "        \n",
    "#         for train, test in folds:\n",
    "#             model = train_als_model(train, factors=factors, reg=reg)\n",
    "            \n",
    "#             # Ensure the test data is in the form of a list of tuples (user, item)\n",
    "#             user_item_pairs = list(test[['user', 'item']].itertuples(index=False, name=None))\n",
    "            \n",
    "#             # Make predictions for these user-item pairs\n",
    "#             pred = model.predict(user_item_pairs)\n",
    "            \n",
    "#             # Calculate RMSE\n",
    "#             rmse_val = util.rmse(pred, test['rating'])\n",
    "#             fold_rmse.append(rmse_val)\n",
    "        \n",
    "#         mean_rmse = sum(fold_rmse) / len(fold_rmse)\n",
    "#         print(f\"Factors: {factors}, Reg: {reg}, RMSE: {mean_rmse}\")\n",
    "        \n",
    "#         if mean_rmse < best_rmse:\n",
    "#             best_rmse = mean_rmse\n",
    "#             best_params = {'factors': factors, 'reg': reg}\n",
    "\n",
    "# print(f\"Best Params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e5a0d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train the model using best hyperparameters from grid search\n",
    "best_algo = train_als_model(train_data, best_params['factors'], best_params['reg'])\n",
    "\n",
    "# Perform cross-validation to evaluate performance\n",
    "fold_rmse = []\n",
    "\n",
    "for train, test in folds:\n",
    "    model = train_als_model(train, best_params['factors'], best_params['reg'])\n",
    "    pred = model.predict(test[['userId', 'movieId']])\n",
    "    rmse_val = util.rmse(pred, test['rating'])\n",
    "    fold_rmse.append(rmse_val)\n",
    "\n",
    "print(f\"Cross-validation RMSE: {sum(fold_rmse)/len(fold_rmse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb542d63",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train on full dataset in batches\n",
    "for offset in range(0, TOTAL_ROWS, BATCH_SIZE):\n",
    "    batch_query = f\"\"\"\n",
    "    SELECT userId, movieId, rating\n",
    "    FROM film-wizard-453315.Grouplens.500k_ratings\n",
    "    ORDER BY userId\n",
    "    LIMIT {BATCH_SIZE} OFFSET {offset}\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_df = client.query(batch_query).to_dataframe()\n",
    "    \n",
    "    if batch_df.empty:\n",
    "        break  # Stop when there are no more rows\n",
    "    \n",
    "    train_data = batch_df[['userId', 'movieId', 'rating']]\n",
    "    \n",
    "    # Train the model on this batch\n",
    "    best_algo.fit(train_data)\n",
    "    print(f\"✅ Processed {offset + BATCH_SIZE} rows\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4286b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predict rating for a specific user and movie\n",
    "user_id = 10531\n",
    "movie_id = 100\n",
    "\n",
    "# Make prediction using the trained ALS model\n",
    "prediction = best_algo.predict(user_id, movie_id)\n",
    "print(f\"Predicted rating for user {user_id} and movie {movie_id}: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fffea9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Notes from original SVD jn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105bd81",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Path to your CSV file\n",
    "csv_path = \"/Users/oliverramsaygray/code/oliverramsaygray/film_wizard/raw_data/Adam films/9a884b4e-8993-4800-925a-bea11dcce39e.csv\"\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "movies_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Convert the 'date' column to datetime if it's not already\n",
    "movies_df['Date'] = pd.to_datetime(movies_df['Date'])\n",
    "\n",
    "# Filter out movies released in or after October 2023\n",
    "movies_df = movies_df[movies_df['Date'] < '2023-10-01']\n",
    "\n",
    "#Filter out movies that Grouplens later has an issue matching with\n",
    "# Exclude specific movies by title\n",
    "movies_to_exclude = [\"Herod's Law\", \"Spirited Away\", \"Sing\", \"Living\", \"Fury\"]  # Replace with actual movie titles\n",
    "movies_df = movies_df[~movies_df['Name'].isin(movies_to_exclude)]\n",
    "\n",
    "##### Half the ratings to be out of 5 - only for Adam #####\n",
    "movies_df['Rating'] = movies_df['Rating']/2\n",
    "\n",
    "# Sort by 'date' in descending order to get the most recent entries\n",
    "oliver_recent_movies = movies_df.sort_values(by='Date', ascending=False).head(10)\n",
    "\n",
    "# Show the most recent 10 movies and their ratings\n",
    "display(oliver_recent_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204bb3b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Set up BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Query to fetch the relevant data from BigQuery\n",
    "query = \"\"\"\n",
    "SELECT movieId, title\n",
    "FROM `film-wizard-453315.Grouplens.grouplens_movies`\n",
    "\"\"\"\n",
    "# Fetch data from BigQuery and load it into a DataFrame\n",
    "grouplens_movies_df = client.query(query).to_dataframe()\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "display('grouplens_movies_df:')\n",
    "display(grouplens_movies_df.head())\n",
    "\n",
    "# Perform fuzzy matching between 'title' in 'oliver_recent_movies' and 'title' in 'grouplens_movies_df'\n",
    "def get_best_match(title, choices, scorer=fuzz.ratio):\n",
    "    \"\"\"Fuzzy match using fuzz.ratio and return the best match.\"\"\"\n",
    "    match = process.extractOne(title, choices, scorer=scorer)\n",
    "    return match[0] if match else None\n",
    "\n",
    "# Apply fuzzy matching to the titles in 'oliver_recent_movies'\n",
    "oliver_recent_movies['matched_title'] = oliver_recent_movies['Name'].apply(\n",
    "    get_best_match, args=(grouplens_movies_df['title'],)\n",
    ")\n",
    "\n",
    "# Merge the original 'oliver_recent_movies' DataFrame with 'grouplens_movies_df' based on the 'matched_title'\n",
    "test_movies_with_ids = pd.merge(\n",
    "    oliver_recent_movies, \n",
    "    grouplens_movies_df[['title', 'movieId']], \n",
    "    left_on='matched_title', \n",
    "    right_on='title', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "##### Drop the 'matched_title' column and any other unnecessary columns - didn't use with Adam's csv\n",
    "# test_movies_with_ids = test_movies_with_ids.drop(columns=['matched_title', 'Letterboxd URI', 'title', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346fbc6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_movies_with_ids.drop_duplicates(inplace=True)\n",
    "\n",
    "# Show the final DataFrame\n",
    "display(test_movies_with_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c109099",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get all movie IDs in the GL dataset (this could be all movies in the system or a smaller list)\n",
    "all_movie_ids = full_gl_df['movieId'].unique()\n",
    "\n",
    "# Find unwatched movies for user 1 (exclude movies that user 1 has already rated)\n",
    "unwatched_movie_ids = [i for i in all_movie_ids if i not in test_movies_with_ids['movieId'].values]\n",
    "\n",
    "# Make predictions for the unwatched movies\n",
    "predictions = [best_algo.predict(1, movie_id) for movie_id in unwatched_movie_ids]\n",
    "\n",
    "# Sort the predictions by predicted rating (descending order)\n",
    "predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "# Extract top X recommended movies with their predicted ratings\n",
    "recommended_movies = [(pred.iid, pred.est) for pred in predictions[:10]]\n",
    "\n",
    "# Convert to DataFrame\n",
    "recommended_df = pd.DataFrame(recommended_movies, columns=[\"Movie ID\", \"Predicted Rating\"])\n",
    "display(recommended_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edde4d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display(recommended_df.info())\n",
    "display(grouplens_movies_df.info())\n",
    "\n",
    "# Bring back titles\n",
    "final_recommendation = pd.merge(\n",
    "    recommended_df, \n",
    "    grouplens_movies_df[['title', 'movieId']], \n",
    "    left_on='Movie ID', \n",
    "    right_on='movieId', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "final_recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af52cb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Understanding the Grouplens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa69832",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Pull table from bq\n",
    "sample_query = \"\"\"\n",
    "SELECT *\n",
    "FROM `film-wizard-453315.Grouplens.grouplens_movies`\n",
    "ORDER BY RAND()\n",
    "LIMIT 1000  -- Adjust for ~1% of 32M rows\n",
    "\"\"\"\n",
    "\n",
    "test_df = client.query(sample_query).to_dataframe()\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eb2ccc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('SVD_film_model.pkl', 'rb') as file:\n",
    "    best_algo_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adea233",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make predictions for the unwatched movies\n",
    "predictions = best_algo.predict(157707, 1)\n",
    "predictions\n",
    "\n",
    "# Sort the predictions by predicted rating (descending order)\n",
    "# predictions.sort(key=lambda x: x.est, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf7389",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69108055",
   "metadata": {},
   "source": [
    "## Online example of Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680fcc28",
   "metadata": {},
   "source": [
    "##### https://medium.com/@ckucewicz21/building-a-simple-movie-recommendation-system-with-surprise-6e61479e1e73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701afaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Load the MovieLens 100k dataset (this is built into Surprise)\n",
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c94936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and test set\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Create the SVD model and train it\n",
    "model = SVD()\n",
    "model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be010389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get top 5 recommendations for a user\n",
    "def get_top_n(predictions, n):\n",
    "    top_n = {}\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid not in top_n:\n",
    "            top_n[uid] = []\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Sort the predictions for each user and return the top n\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    \n",
    "    return top_n\n",
    "\n",
    "# Get predictions for the testset\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Get the top 5 recommendations for each user\n",
    "top_n = get_top_n(predictions, n=50)\n",
    "\n",
    "#-------------------------------\n",
    "\n",
    "# Get top recommendations for a specific user (e.g., user ID = 1)\n",
    "user_id = '825'\n",
    "user_top_n = top_n.get(user_id, [])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_user_top_825 = pd.DataFrame(user_top_n, columns=['Item ID', 'Estimated Rating'])\n",
    "\n",
    "# Get top recommendations for a specific user (e.g., user ID = 1)\n",
    "user_id = '253'\n",
    "user_top_n = top_n.get(user_id, [])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_user_top_253 = pd.DataFrame(user_top_n, columns=['Item ID', 'Estimated Rating'])\n",
    "\n",
    "# Find common Item IDs between the two DataFrames\n",
    "common_item_ids = df_user_top_825[df_user_top_825['Item ID'].isin(df_user_top_253['Item ID'])]\n",
    "\n",
    "# Display the common Item IDs\n",
    "display(common_item_ids)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df_user_top_825, df_user_top_253)\n",
    "\n",
    "# # Print the top 5 recommendations for a specific user (user_id = 1)\n",
    "# print(f\"Top 5 movie recommendations for user 825: {top_n.get('825')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d5a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e03671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top 5 recommendations for a specific user (user_id = 1)\n",
    "print(f\"Top 5 movie recommendations for user 622: {top_n.get('622')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
