{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af89d170",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SVD Grid Search User Review Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e0aa9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:10:16.772302Z",
     "start_time": "2025-03-13T11:10:16.721040Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "print(\"Authenticated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd541f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverramsaygray/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1900: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104833</td>\n",
       "      <td>2470</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161697</td>\n",
       "      <td>551</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170972</td>\n",
       "      <td>239</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147342</td>\n",
       "      <td>1222</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68377</td>\n",
       "      <td>106920</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>5496</td>\n",
       "      <td>4886</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>183343</td>\n",
       "      <td>788</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>66054</td>\n",
       "      <td>1214</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>88500</td>\n",
       "      <td>98836</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>45486</td>\n",
       "      <td>733</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating\n",
       "0       104833     2470     3.0\n",
       "1       161697      551     4.0\n",
       "2       170972      239     3.0\n",
       "3       147342     1222     4.0\n",
       "4        68377   106920     3.0\n",
       "...        ...      ...     ...\n",
       "499995    5496     4886     4.5\n",
       "499996  183343      788     2.5\n",
       "499997   66054     1214     4.0\n",
       "499998   88500    98836     4.0\n",
       "499999   45486      733     4.0\n",
       "\n",
       "[500000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate, GridSearchCV\n",
    "from surprise.accuracy import rmse\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Define BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Define batch size & dataset properties\n",
    "BATCH_SIZE = 100_000  # 100k rows per batch\n",
    "TOTAL_ROWS = 500_000  # Approximate total dataset size\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "\n",
    "### **GL df with  500k randomly sampled ratings**\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `film-wizard-453315.Grouplens.500k_ratings`\n",
    "ORDER BY RAND()\n",
    "\"\"\"\n",
    "sample_gl_df = client.query(sample_query).to_dataframe()\n",
    "sample_gl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd1b3620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverramsaygray/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1900: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_factors': 10, 'reg_all': 0.05}\n"
     ]
    }
   ],
   "source": [
    "### **1️⃣ Perform Grid Search on Small Sample**\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `film-wizard-453315.Grouplens.500k_ratings`\n",
    "ORDER BY RAND()\n",
    "LIMIT 100000  -- Adjust for ~20% of 500k rows\n",
    "\"\"\"\n",
    "grid_search_df = client.query(sample_query).to_dataframe()\n",
    "data = Dataset.load_from_df(grid_search_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    \"n_factors\": [10, 20, 50],  \n",
    "    \"reg_all\": [0.001, 0.01, 0.05]  \n",
    "}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\"], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "best_params = gs.best_params[\"rmse\"]\n",
    "print(\"Best Params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb2c819",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9761  0.9824  0.9737  0.9766  0.9722  0.9762  0.0035  \n",
      "MAE (testset)     0.7543  0.7612  0.7536  0.7537  0.7512  0.7548  0.0034  \n",
      "Fit time          0.55    0.54    0.59    0.58    0.58    0.57    0.02    \n",
      "Test time         0.09    0.18    0.10    0.10    0.09    0.11    0.03    \n",
      "{'test_rmse': array([0.97608594, 0.98239046, 0.97367309, 0.97655714, 0.97222009]), 'test_mae': array([0.75425928, 0.76122421, 0.75359025, 0.75365902, 0.75120742]), 'fit_time': (0.5457689762115479, 0.5390288829803467, 0.5860280990600586, 0.5803048610687256, 0.5773000717163086), 'test_time': (0.09341812133789062, 0.1780092716217041, 0.09600687026977539, 0.0960841178894043, 0.09351706504821777)}\n"
     ]
    }
   ],
   "source": [
    "# **2️⃣ Cross-Validation Before Batch Training**\n",
    "best_algo = SVD(n_factors=best_params[\"n_factors\"], reg_all=best_params[\"reg_all\"])\n",
    "cv_results = cross_validate(best_algo, data, cv=5, verbose=True)\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d8ff79f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverramsaygray/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1900: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 100000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverramsaygray/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1900: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 200000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverramsaygray/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1900: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 300000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverramsaygray/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1900: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 400000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverramsaygray/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1900: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 500000 rows\n"
     ]
    }
   ],
   "source": [
    "# **3️⃣ Train on Full Dataset in Batches**\n",
    "for offset in range(0, TOTAL_ROWS, BATCH_SIZE):\n",
    "    batch_query = f\"\"\"\n",
    "    SELECT userId, movieId, rating\n",
    "    FROM `film-wizard-453315.Grouplens.500k_ratings`\n",
    "    ORDER BY userId\n",
    "    LIMIT {BATCH_SIZE} OFFSET {offset}\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_df = client.query(batch_query).to_dataframe()\n",
    "    \n",
    "    if batch_df.empty:\n",
    "        break  # Stop when there are no more rows\n",
    "    \n",
    "    dataset = Dataset.load_from_df(batch_df[['userId', 'movieId', 'rating']], reader)\n",
    "    trainset = dataset.build_full_trainset()\n",
    "    \n",
    "    best_algo.fit(trainset)\n",
    "    print(f\"✅ Processed {offset + BATCH_SIZE} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53d47138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverramsaygray/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1900: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9608\n",
      "Final RMSE on test set: 0.9607709766743512\n"
     ]
    }
   ],
   "source": [
    "### **4️⃣ Evaluate Best Model on a Fresh Test Set**\n",
    "test_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `film-wizard-453315.Grouplens.500k_ratings`\n",
    "ORDER BY RAND()\n",
    "LIMIT 1500000  -- Adjust for ~5% of 32M rows\n",
    "\"\"\"\n",
    "test_df = client.query(test_query).to_dataframe()\n",
    "testset = Dataset.load_from_df(test_df[['userId', 'movieId', 'rating']], reader).build_full_trainset().build_testset()\n",
    "\n",
    "predictions = best_algo.test(testset)\n",
    "print(\"Final RMSE on test set:\", rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b5f88ee",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=10531, iid=100, r_ui=None, est=3.401492923710541, details={'was_impossible': False})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = best_algo.predict(10531, 100)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b179c1",
   "metadata": {},
   "source": [
    "## Lenskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb2f710a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lenskit.als'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlenskit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m crossfold\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlenskit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BiasedMFScorer\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlenskit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Initialize BigQuery client\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lenskit.als'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from lenskit import crossfold\n",
    "from lenskit.als import BiasedMFScorer # https://lkpy.lenskit.org/stable/guide/gettingstarted\n",
    "from lenskit import util\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "print(\"Authenticated successfully!\")\n",
    "\n",
    "# Define batch size & dataset properties\n",
    "BATCH_SIZE = 100_000  # 100k rows per batch\n",
    "TOTAL_ROWS = 500_000  # Approximate total dataset size\n",
    "\n",
    "# Fetch 500k ratings from BigQuery randomly (for the entire dataset)\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM film-wizard-453315.Grouplens.500k_ratings\n",
    "ORDER BY RAND()\n",
    "\"\"\"\n",
    "sample_gl_df = client.query(sample_query).to_dataframe()\n",
    "\n",
    "# Rename columns to match LensKit's expected column names\n",
    "sample_gl_df = sample_gl_df.rename(columns={'userId': 'user_id', 'movieId': 'item_id'})\n",
    "sample_gl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcf2491e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m als\u001b[38;5;241m.\u001b[39mBiasedMF(features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, reg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, rng_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Fit the model with your data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_gl_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mitem_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create a scorer from the model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m scorer \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mscorer()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/lenskit/algorithms/als.py:376\u001b[0m, in \u001b[0;36mBiasedMF.fit\u001b[0;34m(self, ratings, **kwargs)\u001b[0m\n\u001b[1;32m    373\u001b[0m util\u001b[38;5;241m.\u001b[39mcheck_env()\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimer \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mStopwatch()\n\u001b[0;32m--> 376\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch, algo \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_iters(ratings, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)):\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# we just need to do the iterations\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_features_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/lenskit/algorithms/als.py:403\u001b[0m, in \u001b[0;36mBiasedMF.fit_iters\u001b[0;34m(self, ratings, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias:\n\u001b[1;32m    402\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m] fitting bias model\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimer)\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m current, uctx, ictx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_model(ratings)\n\u001b[1;32m    407\u001b[0m _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m] training biased MF model with ALS for \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m features\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    408\u001b[0m              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/lenskit/algorithms/bias.py:81\u001b[0m, in \u001b[0;36mBias.fit\u001b[0;34m(self, ratings, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m nrates \u001b[38;5;241m=\u001b[39m ratings\u001b[38;5;241m.\u001b[39massign(rating\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m df: df\u001b[38;5;241m.\u001b[39mrating \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems:\n\u001b[0;32m---> 81\u001b[0m     group \u001b[38;5;241m=\u001b[39m \u001b[43mnrates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mitem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrating\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_offsets_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mean(group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_damping)\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_offsets_\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi_off\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/pandas/core/frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'item'"
     ]
    }
   ],
   "source": [
    "# I ned to define cv, hyperparam grid and then do a gridsearch\n",
    "\n",
    "# Train the model\n",
    "model = als.BiasedMF(features=3, reg=0.01, rng_spec=42)\n",
    "\n",
    "# Fit the model with your data\n",
    "model.fit(sample_gl_df[['user_id', 'item_id', 'rating']])\n",
    "\n",
    "# Create a scorer from the model\n",
    "scorer = model.scorer()\n",
    "\n",
    "# # ---------------------------\n",
    "\n",
    "# # Prepare data for training\n",
    "# train_data = sample_gl_df[['user', 'item', 'rating']]\n",
    "\n",
    "# # Define cross-validation with LensKit\n",
    "# folds = crossfold.sample_users(train_data, 5, size=0.2, method='random')  # 5-fold cross-validation\n",
    "\n",
    "# # Define a function for ALS model training\n",
    "# def train_als_model(train_data, factors=10, reg=0.01):\n",
    "#     algo = als.ALS(factors=factors, reg=reg, random_state=42)\n",
    "#     algo.fit(train_data)\n",
    "#     return algo\n",
    "\n",
    "# # Example hyperparameter grid (number of factors and regularization)\n",
    "# param_grid = {\n",
    "#     \"factors\": [5, 10, 50],\n",
    "#     \"reg\": [0.001, 0.01, 0.05]\n",
    "# }\n",
    "\n",
    "# # Manually grid search\n",
    "# best_rmse = float('inf')\n",
    "# best_params = {}\n",
    "\n",
    "# for factors in param_grid[\"factors\"]:\n",
    "#     for reg in param_grid[\"reg\"]:\n",
    "#         fold_rmse = []\n",
    "        \n",
    "#         for train, test in folds:\n",
    "#             model = train_als_model(train, factors=factors, reg=reg)\n",
    "            \n",
    "#             # Ensure the test data is in the form of a list of tuples (user, item)\n",
    "#             user_item_pairs = list(test[['user', 'item']].itertuples(index=False, name=None))\n",
    "            \n",
    "#             # Make predictions for these user-item pairs\n",
    "#             pred = model.predict(user_item_pairs)\n",
    "            \n",
    "#             # Calculate RMSE\n",
    "#             rmse_val = util.rmse(pred, test['rating'])\n",
    "#             fold_rmse.append(rmse_val)\n",
    "        \n",
    "#         mean_rmse = sum(fold_rmse) / len(fold_rmse)\n",
    "#         print(f\"Factors: {factors}, Reg: {reg}, RMSE: {mean_rmse}\")\n",
    "        \n",
    "#         if mean_rmse < best_rmse:\n",
    "#             best_rmse = mean_rmse\n",
    "#             best_params = {'factors': factors, 'reg': reg}\n",
    "\n",
    "# print(f\"Best Params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e5a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using best hyperparameters from grid search\n",
    "best_algo = train_als_model(train_data, best_params['factors'], best_params['reg'])\n",
    "\n",
    "# Perform cross-validation to evaluate performance\n",
    "fold_rmse = []\n",
    "\n",
    "for train, test in folds:\n",
    "    model = train_als_model(train, best_params['factors'], best_params['reg'])\n",
    "    pred = model.predict(test[['userId', 'movieId']])\n",
    "    rmse_val = util.rmse(pred, test['rating'])\n",
    "    fold_rmse.append(rmse_val)\n",
    "\n",
    "print(f\"Cross-validation RMSE: {sum(fold_rmse)/len(fold_rmse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb542d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on full dataset in batches\n",
    "for offset in range(0, TOTAL_ROWS, BATCH_SIZE):\n",
    "    batch_query = f\"\"\"\n",
    "    SELECT userId, movieId, rating\n",
    "    FROM film-wizard-453315.Grouplens.500k_ratings\n",
    "    ORDER BY userId\n",
    "    LIMIT {BATCH_SIZE} OFFSET {offset}\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_df = client.query(batch_query).to_dataframe()\n",
    "    \n",
    "    if batch_df.empty:\n",
    "        break  # Stop when there are no more rows\n",
    "    \n",
    "    train_data = batch_df[['userId', 'movieId', 'rating']]\n",
    "    \n",
    "    # Train the model on this batch\n",
    "    best_algo.fit(train_data)\n",
    "    print(f\"✅ Processed {offset + BATCH_SIZE} rows\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict rating for a specific user and movie\n",
    "user_id = 10531\n",
    "movie_id = 100\n",
    "\n",
    "# Make prediction using the trained ALS model\n",
    "prediction = best_algo.predict(user_id, movie_id)\n",
    "print(f\"Predicted rating for user {user_id} and movie {movie_id}: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fffea9",
   "metadata": {},
   "source": [
    "## Notes from original SVD jn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your CSV file\n",
    "csv_path = \"/Users/oliverramsaygray/code/oliverramsaygray/film_wizard/raw_data/Adam films/9a884b4e-8993-4800-925a-bea11dcce39e.csv\"\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "movies_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Convert the 'date' column to datetime if it's not already\n",
    "movies_df['Date'] = pd.to_datetime(movies_df['Date'])\n",
    "\n",
    "# Filter out movies released in or after October 2023\n",
    "movies_df = movies_df[movies_df['Date'] < '2023-10-01']\n",
    "\n",
    "#Filter out movies that Grouplens later has an issue matching with\n",
    "# Exclude specific movies by title\n",
    "movies_to_exclude = [\"Herod's Law\", \"Spirited Away\", \"Sing\", \"Living\", \"Fury\"]  # Replace with actual movie titles\n",
    "movies_df = movies_df[~movies_df['Name'].isin(movies_to_exclude)]\n",
    "\n",
    "##### Half the ratings to be out of 5 - only for Adam #####\n",
    "movies_df['Rating'] = movies_df['Rating']/2\n",
    "\n",
    "# Sort by 'date' in descending order to get the most recent entries\n",
    "oliver_recent_movies = movies_df.sort_values(by='Date', ascending=False).head(10)\n",
    "\n",
    "# Show the most recent 10 movies and their ratings\n",
    "display(oliver_recent_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Set up BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Query to fetch the relevant data from BigQuery\n",
    "query = \"\"\"\n",
    "SELECT movieId, title\n",
    "FROM `film-wizard-453315.Grouplens.grouplens_movies`\n",
    "\"\"\"\n",
    "# Fetch data from BigQuery and load it into a DataFrame\n",
    "grouplens_movies_df = client.query(query).to_dataframe()\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "display('grouplens_movies_df:')\n",
    "display(grouplens_movies_df.head())\n",
    "\n",
    "# Perform fuzzy matching between 'title' in 'oliver_recent_movies' and 'title' in 'grouplens_movies_df'\n",
    "def get_best_match(title, choices, scorer=fuzz.ratio):\n",
    "    \"\"\"Fuzzy match using fuzz.ratio and return the best match.\"\"\"\n",
    "    match = process.extractOne(title, choices, scorer=scorer)\n",
    "    return match[0] if match else None\n",
    "\n",
    "# Apply fuzzy matching to the titles in 'oliver_recent_movies'\n",
    "oliver_recent_movies['matched_title'] = oliver_recent_movies['Name'].apply(\n",
    "    get_best_match, args=(grouplens_movies_df['title'],)\n",
    ")\n",
    "\n",
    "# Merge the original 'oliver_recent_movies' DataFrame with 'grouplens_movies_df' based on the 'matched_title'\n",
    "test_movies_with_ids = pd.merge(\n",
    "    oliver_recent_movies, \n",
    "    grouplens_movies_df[['title', 'movieId']], \n",
    "    left_on='matched_title', \n",
    "    right_on='title', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "##### Drop the 'matched_title' column and any other unnecessary columns - didn't use with Adam's csv\n",
    "# test_movies_with_ids = test_movies_with_ids.drop(columns=['matched_title', 'Letterboxd URI', 'title', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movies_with_ids.drop_duplicates(inplace=True)\n",
    "\n",
    "# Show the final DataFrame\n",
    "display(test_movies_with_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c109099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all movie IDs in the GL dataset (this could be all movies in the system or a smaller list)\n",
    "all_movie_ids = full_gl_df['movieId'].unique()\n",
    "\n",
    "# Find unwatched movies for user 1 (exclude movies that user 1 has already rated)\n",
    "unwatched_movie_ids = [i for i in all_movie_ids if i not in test_movies_with_ids['movieId'].values]\n",
    "\n",
    "# Make predictions for the unwatched movies\n",
    "predictions = [best_algo.predict(1, movie_id) for movie_id in unwatched_movie_ids]\n",
    "\n",
    "# Sort the predictions by predicted rating (descending order)\n",
    "predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "# Extract top X recommended movies with their predicted ratings\n",
    "recommended_movies = [(pred.iid, pred.est) for pred in predictions[:10]]\n",
    "\n",
    "# Convert to DataFrame\n",
    "recommended_df = pd.DataFrame(recommended_movies, columns=[\"Movie ID\", \"Predicted Rating\"])\n",
    "display(recommended_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edde4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(recommended_df.info())\n",
    "display(grouplens_movies_df.info())\n",
    "\n",
    "# Bring back titles\n",
    "final_recommendation = pd.merge(\n",
    "    recommended_df, \n",
    "    grouplens_movies_df[['title', 'movieId']], \n",
    "    left_on='Movie ID', \n",
    "    right_on='movieId', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "final_recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af52cb",
   "metadata": {},
   "source": [
    "## Understanding the Grouplens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa69832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Pull table from bq\n",
    "sample_query = \"\"\"\n",
    "SELECT *\n",
    "FROM `film-wizard-453315.Grouplens.grouplens_movies`\n",
    "ORDER BY RAND()\n",
    "LIMIT 1000  -- Adjust for ~1% of 32M rows\n",
    "\"\"\"\n",
    "\n",
    "test_df = client.query(sample_query).to_dataframe()\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eb2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('SVD_film_model.pkl', 'rb') as file:\n",
    "    best_algo_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adea233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the unwatched movies\n",
    "predictions = best_algo.predict(157707, 1)\n",
    "predictions\n",
    "\n",
    "# Sort the predictions by predicted rating (descending order)\n",
    "# predictions.sort(key=lambda x: x.est, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf7389",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701afaed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
