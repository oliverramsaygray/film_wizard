{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44eb6df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "print(\"Authenticated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a16182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverramsaygray/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1900: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from surprise.accuracy import rmse\n",
    "import pandas as pd\n",
    "\n",
    "# Define BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Define batch size & dataset properties\n",
    "BATCH_SIZE = 1_000_000  # 100k rows per batch\n",
    "TOTAL_ROWS = 32_000_000  # Approximate total dataset size\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "\n",
    "### **GL df**\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `film-wizard-453315.Grouplens.raw_grouplens_ratings`\n",
    "ORDER BY RAND()\n",
    "LIMIT 10000000\n",
    "\"\"\"\n",
    "\n",
    "# Fetch data from BigQuery\n",
    "gl_df = client.query(sample_query).to_dataframe()\n",
    "print(\"Loaded data from BigQuery:\", gl_df.shape)\n",
    "display(gl_df.head(5))\n",
    "\n",
    "data = Dataset.load_from_df(gl_df, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b2be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and test set\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Create the SVD model and train it\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Define a function to get top 5 recommendations for a user\n",
    "def get_top_n(predictions, n):\n",
    "    top_n = {}\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid not in top_n:\n",
    "            top_n[uid] = []\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Sort the predictions for each user and return the top n\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    \n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **2️⃣ Cross-Validation Before Batch Training**\n",
    "cv_results = cross_validate(model, data, cv=5, verbose=True)\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1685ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for the testset\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Get the top 5 recommendations for each user\n",
    "top_n = get_top_n(predictions, n=3)\n",
    "top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92e9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2005778",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\n",
    "    132721: [(3030, 4.343930472863401),\n",
    "  (3147, 4.173104100455896),\n",
    "  (8014, 4.10402787200236)],\n",
    " 134273: [(69481, 3.2115050041528552),\n",
    "  (2917, 3.147696080876573),\n",
    "  (1227, 3.14304677816368)],\n",
    " 163615: [(1196, 4.082660659362825),\n",
    "  (7099, 4.038083503624332),\n",
    "  (608, 3.769995671477647)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8363bb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(132721, [(3030, 4.343930472863401), (3147, 4.173104100455896), (8014, 4.10402787200236)]), (134273, [(69481, 3.2115050041528552), (2917, 3.147696080876573), (1227, 3.14304677816368)]), (163615, [(1196, 4.082660659362825), (7099, 4.038083503624332), (608, 3.769995671477647)])])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fffb20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40879</td>\n",
       "      <td>55820</td>\n",
       "      <td>4.128208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168229</td>\n",
       "      <td>7293</td>\n",
       "      <td>3.711152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>168229</td>\n",
       "      <td>45</td>\n",
       "      <td>3.629812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168229</td>\n",
       "      <td>7369</td>\n",
       "      <td>2.798608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199867</td>\n",
       "      <td>1258</td>\n",
       "      <td>3.693651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179343</th>\n",
       "      <td>160163</td>\n",
       "      <td>33794</td>\n",
       "      <td>4.018429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179344</th>\n",
       "      <td>192996</td>\n",
       "      <td>1097</td>\n",
       "      <td>4.099539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179345</th>\n",
       "      <td>94107</td>\n",
       "      <td>1784</td>\n",
       "      <td>3.515356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179346</th>\n",
       "      <td>25021</td>\n",
       "      <td>8981</td>\n",
       "      <td>4.088357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179347</th>\n",
       "      <td>52596</td>\n",
       "      <td>69757</td>\n",
       "      <td>3.513463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179348 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId    rating\n",
       "0        40879    55820  4.128208\n",
       "1       168229     7293  3.711152\n",
       "2       168229       45  3.629812\n",
       "3       168229     7369  2.798608\n",
       "4       199867     1258  3.693651\n",
       "...        ...      ...       ...\n",
       "179343  160163    33794  4.018429\n",
       "179344  192996     1097  4.099539\n",
       "179345   94107     1784  3.515356\n",
       "179346   25021     8981  4.088357\n",
       "179347   52596    69757  3.513463\n",
       "\n",
       "[179348 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert user recommendations into a single DataFrame\n",
    "data = []\n",
    "for user_id, movies in top_n.items():\n",
    "    for movie_id, rating in movies:\n",
    "        data.append((user_id, movie_id, rating))\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"userId\", \"movieId\", \"rating\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21f99840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userId  movieId    rating\n",
      "0        40879    55820  4.128208\n",
      "1       168229     7293  3.711152\n",
      "2       168229       45  3.629812\n",
      "3       168229     7369  2.798608\n",
      "4       199867     1258  3.693651\n",
      "...        ...      ...       ...\n",
      "179343  160163    33794  4.018429\n",
      "179344  192996     1097  4.099539\n",
      "179345   94107     1784  3.515356\n",
      "179346   25021     8981  4.088357\n",
      "179347   52596    69757  3.513463\n",
      "\n",
      "[175566 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each movieId\n",
    "movie_counts = df['movieId'].value_counts()\n",
    "\n",
    "# Filter rows where movieId appears more than once\n",
    "duplicated_movies_df = df[df['movieId'].isin(movie_counts[movie_counts > 1].index)]\n",
    "\n",
    "print(duplicated_movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1d44dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40879</td>\n",
       "      <td>55820</td>\n",
       "      <td>4.128208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>51129</td>\n",
       "      <td>55820</td>\n",
       "      <td>4.270827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>22363</td>\n",
       "      <td>55820</td>\n",
       "      <td>4.324430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>118615</td>\n",
       "      <td>55820</td>\n",
       "      <td>4.223380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>67014</td>\n",
       "      <td>55820</td>\n",
       "      <td>3.843142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176773</th>\n",
       "      <td>38040</td>\n",
       "      <td>55820</td>\n",
       "      <td>3.836318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177121</th>\n",
       "      <td>181651</td>\n",
       "      <td>55820</td>\n",
       "      <td>4.039910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177388</th>\n",
       "      <td>144154</td>\n",
       "      <td>55820</td>\n",
       "      <td>4.156675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177864</th>\n",
       "      <td>55089</td>\n",
       "      <td>55820</td>\n",
       "      <td>4.421721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178412</th>\n",
       "      <td>126499</td>\n",
       "      <td>55820</td>\n",
       "      <td>4.072171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId    rating\n",
       "0        40879    55820  4.128208\n",
       "892      51129    55820  4.270827\n",
       "1430     22363    55820  4.324430\n",
       "3978    118615    55820  4.223380\n",
       "4475     67014    55820  3.843142\n",
       "...        ...      ...       ...\n",
       "176773   38040    55820  3.836318\n",
       "177121  181651    55820  4.039910\n",
       "177388  144154    55820  4.156675\n",
       "177864   55089    55820  4.421721\n",
       "178412  126499    55820  4.072171\n",
       "\n",
       "[224 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['movieId'] == 55820]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dbeddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {\n",
    "    'userId': [132721],\n",
    "    'movieId': [3030],\n",
    "    'rating': [4.343930472863401]\n",
    "}\n",
    "\n",
    "test_df = pd.DataFrame(data=test_dict)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8634703e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b785d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store DataFrames\n",
    "user_dfs = {}\n",
    "\n",
    "# Loop through each userId and create a DataFrame\n",
    "for user_id in top_n:\n",
    "    movie_data = top_n[user_id]  # Get movie list for the user\n",
    "    movie_ids = []\n",
    "    predicted_ratings = []\n",
    "    \n",
    "    # Extract movieId and predicted_rating\n",
    "    for movie in movie_data:\n",
    "        movie_ids.append(movie[0])\n",
    "        predicted_ratings.append(movie[1])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\"movieId\": movie_ids, \"predicted_rating\": predicted_ratings})\n",
    "    \n",
    "    # Store in dictionary\n",
    "    user_dfs[user_id] = df\n",
    "\n",
    "# Display example output\n",
    "for user_id in user_dfs:\n",
    "    print(f\"User {user_id} recommendations:\")\n",
    "    print(user_dfs[user_id], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2b61ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a94537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af89d170",
   "metadata": {},
   "source": [
    "## SVD Grid Search User Review Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e0aa9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:10:16.772302Z",
     "start_time": "2025-03-13T11:10:16.721040Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "print(\"Authenticated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd541f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    }
   },
   "outputs": [],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate, GridSearchCV\n",
    "from surprise.accuracy import rmse\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Define BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Define batch size & dataset properties\n",
    "BATCH_SIZE = 100_000  # 100k rows per batch\n",
    "TOTAL_ROWS = 500_000  # Approximate total dataset size\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "\n",
    "### **GL df with  500k randomly sampled ratings**\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `film-wizard-453315.Grouplens.500k_ratings`\n",
    "ORDER BY RAND()\n",
    "\"\"\"\n",
    "sample_gl_df = client.query(sample_query).to_dataframe()\n",
    "sample_gl_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(sample_gl_df, reader)\n",
    "\n",
    "# Split the data into a training and test set\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Create the SVD model and train it\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Define a function to get top 5 recommendations for a user\n",
    "def get_top_n(predictions, n):\n",
    "    top_n = {}\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid not in top_n:\n",
    "            top_n[uid] = []\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Sort the predictions for each user and return the top n\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    \n",
    "    return top_n\n",
    "\n",
    "# **2️⃣ Cross-Validation Before Batch Training**\n",
    "cv_results = cross_validate(model, data, cv=5, verbose=True)\n",
    "print(cv_results)\n",
    "\n",
    "# Get predictions for the testset\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Get the top 5 recommendations for each user\n",
    "top_n = get_top_n(predictions, n=50)\n",
    "top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d64acb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "grouped_rating_df = sample_gl_df.groupby(by='movieId').count().sort_values(by='movieId', ascending=True)\n",
    "display(grouped_rating_df)\n",
    "\n",
    "# sns.histplot(data=grouped_rating_df, x='movieId')\n",
    "\n",
    "# sample_gl_df['quartile'] = pd.qcut(sample_gl_df['rating'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "# sample_gl_df\n",
    "\n",
    "# sample_gl_df.groupby(by='quartile').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd64cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = sample_gl_df.groupby('movieId').count().reset_index(names='num_reviews')\n",
    "grouped_df\n",
    "\n",
    "# grouped_df['quartile'] = pd.qcut(grouped_df['num_reviews'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "# group_df['quartile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b3620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    }
   },
   "outputs": [],
   "source": [
    "### **1️⃣ Perform Grid Search on Small Sample**\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `film-wizard-453315.Grouplens.500k_ratings`\n",
    "ORDER BY RAND()\n",
    "LIMIT 100000  -- Adjust for ~20% of 500k rows\n",
    "\"\"\"\n",
    "grid_search_df = client.query(sample_query).to_dataframe()\n",
    "data = Dataset.load_from_df(grid_search_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    \"n_factors\": [10, 20, 50],  \n",
    "    \"reg_all\": [0.01, 0.03, 0.05]  \n",
    "}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\"], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "best_params = gs.best_params[\"rmse\"]\n",
    "print(\"Best Params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb2c819",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    }
   },
   "outputs": [],
   "source": [
    "# **2️⃣ Cross-Validation Before Batch Training**\n",
    "best_algo = SVD(n_factors=best_params[\"n_factors\"], reg_all=best_params[\"reg_all\"])\n",
    "cv_results = cross_validate(best_algo, data, cv=5, verbose=True)\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8ff79f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    }
   },
   "outputs": [],
   "source": [
    "# **3️⃣ Train on Full Dataset in Batches**\n",
    "for offset in range(0, TOTAL_ROWS, BATCH_SIZE):\n",
    "    batch_query = f\"\"\"\n",
    "    SELECT userId, movieId, rating\n",
    "    FROM `film-wizard-453315.Grouplens.500k_ratings`\n",
    "    ORDER BY userId\n",
    "    LIMIT {BATCH_SIZE} OFFSET {offset}\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_df = client.query(batch_query).to_dataframe()\n",
    "    \n",
    "    if batch_df.empty:\n",
    "        break  # Stop when there are no more rows\n",
    "    \n",
    "    dataset = Dataset.load_from_df(batch_df[['userId', 'movieId', 'rating']], reader)\n",
    "    trainset = dataset.build_full_trainset()\n",
    "    \n",
    "    best_algo.fit(trainset)\n",
    "    print(f\"✅ Processed {offset + BATCH_SIZE} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d47138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    }
   },
   "outputs": [],
   "source": [
    "### **4️⃣ Evaluate Best Model on a Fresh Test Set**\n",
    "test_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `film-wizard-453315.Grouplens.500k_ratings`\n",
    "ORDER BY RAND()\n",
    "LIMIT 1500000  -- Adjust for ~5% of 32M rows\n",
    "\"\"\"\n",
    "test_df = client.query(test_query).to_dataframe()\n",
    "testset = Dataset.load_from_df(test_df[['userId', 'movieId', 'rating']], reader).build_full_trainset().build_testset()\n",
    "\n",
    "predictions = best_algo.test(testset)\n",
    "print(\"Final RMSE on test set:\", rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221fa27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieId_list = sample_gl_df['movieId']\n",
    "\n",
    "predictions_list = []\n",
    "\n",
    "for x in movieId_list:\n",
    "    predictions = best_algo.predict(2000, x)\n",
    "    predictions_list.append(predictions)\n",
    "    \n",
    "predictions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f88ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract movie IDs (iid) and predicted ratings (est)\n",
    "movie_ids = [pred.iid for pred in predictions_list]\n",
    "est_values = [pred.est for pred in predictions_list]\n",
    "\n",
    "# Plot the predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(movie_ids, est_values, alpha=0.5)\n",
    "plt.xlabel(\"Movie ID\")\n",
    "plt.ylabel(\"Predicted Rating (est)\")\n",
    "plt.title(\"Predicted Ratings for Each Movie\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b179c1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Lenskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f710a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from lenskit import crossfold\n",
    "from lenskit.als import BiasedMFScorer # https://lkpy.lenskit.org/stable/guide/gettingstarted\n",
    "from lenskit import util\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "print(\"Authenticated successfully!\")\n",
    "\n",
    "# Define batch size & dataset properties\n",
    "BATCH_SIZE = 100_000  # 100k rows per batch\n",
    "TOTAL_ROWS = 500_000  # Approximate total dataset size\n",
    "\n",
    "# Fetch 500k ratings from BigQuery randomly (for the entire dataset)\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM film-wizard-453315.Grouplens.500k_ratings\n",
    "ORDER BY RAND()\n",
    "\"\"\"\n",
    "sample_gl_df = client.query(sample_query).to_dataframe()\n",
    "\n",
    "# Rename columns to match LensKit's expected column names\n",
    "sample_gl_df = sample_gl_df.rename(columns={'userId': 'user_id', 'movieId': 'item_id'})\n",
    "sample_gl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf2491e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# I ned to define cv, hyperparam grid and then do a gridsearch\n",
    "\n",
    "# Train the model\n",
    "model = als.BiasedMF(features=3, reg=0.01, rng_spec=42)\n",
    "\n",
    "# Fit the model with your data\n",
    "model.fit(sample_gl_df[['user_id', 'item_id', 'rating']])\n",
    "\n",
    "# Create a scorer from the model\n",
    "scorer = model.scorer()\n",
    "\n",
    "# # ---------------------------\n",
    "\n",
    "# # Prepare data for training\n",
    "# train_data = sample_gl_df[['user', 'item', 'rating']]\n",
    "\n",
    "# # Define cross-validation with LensKit\n",
    "# folds = crossfold.sample_users(train_data, 5, size=0.2, method='random')  # 5-fold cross-validation\n",
    "\n",
    "# # Define a function for ALS model training\n",
    "# def train_als_model(train_data, factors=10, reg=0.01):\n",
    "#     algo = als.ALS(factors=factors, reg=reg, random_state=42)\n",
    "#     algo.fit(train_data)\n",
    "#     return algo\n",
    "\n",
    "# # Example hyperparameter grid (number of factors and regularization)\n",
    "# param_grid = {\n",
    "#     \"factors\": [5, 10, 50],\n",
    "#     \"reg\": [0.001, 0.01, 0.05]\n",
    "# }\n",
    "\n",
    "# # Manually grid search\n",
    "# best_rmse = float('inf')\n",
    "# best_params = {}\n",
    "\n",
    "# for factors in param_grid[\"factors\"]:\n",
    "#     for reg in param_grid[\"reg\"]:\n",
    "#         fold_rmse = []\n",
    "        \n",
    "#         for train, test in folds:\n",
    "#             model = train_als_model(train, factors=factors, reg=reg)\n",
    "            \n",
    "#             # Ensure the test data is in the form of a list of tuples (user, item)\n",
    "#             user_item_pairs = list(test[['user', 'item']].itertuples(index=False, name=None))\n",
    "            \n",
    "#             # Make predictions for these user-item pairs\n",
    "#             pred = model.predict(user_item_pairs)\n",
    "            \n",
    "#             # Calculate RMSE\n",
    "#             rmse_val = util.rmse(pred, test['rating'])\n",
    "#             fold_rmse.append(rmse_val)\n",
    "        \n",
    "#         mean_rmse = sum(fold_rmse) / len(fold_rmse)\n",
    "#         print(f\"Factors: {factors}, Reg: {reg}, RMSE: {mean_rmse}\")\n",
    "        \n",
    "#         if mean_rmse < best_rmse:\n",
    "#             best_rmse = mean_rmse\n",
    "#             best_params = {'factors': factors, 'reg': reg}\n",
    "\n",
    "# print(f\"Best Params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e5a0d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train the model using best hyperparameters from grid search\n",
    "best_algo = train_als_model(train_data, best_params['factors'], best_params['reg'])\n",
    "\n",
    "# Perform cross-validation to evaluate performance\n",
    "fold_rmse = []\n",
    "\n",
    "for train, test in folds:\n",
    "    model = train_als_model(train, best_params['factors'], best_params['reg'])\n",
    "    pred = model.predict(test[['userId', 'movieId']])\n",
    "    rmse_val = util.rmse(pred, test['rating'])\n",
    "    fold_rmse.append(rmse_val)\n",
    "\n",
    "print(f\"Cross-validation RMSE: {sum(fold_rmse)/len(fold_rmse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb542d63",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train on full dataset in batches\n",
    "for offset in range(0, TOTAL_ROWS, BATCH_SIZE):\n",
    "    batch_query = f\"\"\"\n",
    "    SELECT userId, movieId, rating\n",
    "    FROM film-wizard-453315.Grouplens.500k_ratings\n",
    "    ORDER BY userId\n",
    "    LIMIT {BATCH_SIZE} OFFSET {offset}\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_df = client.query(batch_query).to_dataframe()\n",
    "    \n",
    "    if batch_df.empty:\n",
    "        break  # Stop when there are no more rows\n",
    "    \n",
    "    train_data = batch_df[['userId', 'movieId', 'rating']]\n",
    "    \n",
    "    # Train the model on this batch\n",
    "    best_algo.fit(train_data)\n",
    "    print(f\"✅ Processed {offset + BATCH_SIZE} rows\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4286b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predict rating for a specific user and movie\n",
    "user_id = 10531\n",
    "movie_id = 100\n",
    "\n",
    "# Make prediction using the trained ALS model\n",
    "prediction = best_algo.predict(user_id, movie_id)\n",
    "print(f\"Predicted rating for user {user_id} and movie {movie_id}: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fffea9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Notes from original SVD jn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105bd81",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Path to your CSV file\n",
    "csv_path = \"/Users/oliverramsaygray/code/oliverramsaygray/film_wizard/raw_data/Adam films/9a884b4e-8993-4800-925a-bea11dcce39e.csv\"\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "movies_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Convert the 'date' column to datetime if it's not already\n",
    "movies_df['Date'] = pd.to_datetime(movies_df['Date'])\n",
    "\n",
    "# Filter out movies released in or after October 2023\n",
    "movies_df = movies_df[movies_df['Date'] < '2023-10-01']\n",
    "\n",
    "#Filter out movies that Grouplens later has an issue matching with\n",
    "# Exclude specific movies by title\n",
    "movies_to_exclude = [\"Herod's Law\", \"Spirited Away\", \"Sing\", \"Living\", \"Fury\"]  # Replace with actual movie titles\n",
    "movies_df = movies_df[~movies_df['Name'].isin(movies_to_exclude)]\n",
    "\n",
    "##### Half the ratings to be out of 5 - only for Adam #####\n",
    "movies_df['Rating'] = movies_df['Rating']/2\n",
    "\n",
    "# Sort by 'date' in descending order to get the most recent entries\n",
    "oliver_recent_movies = movies_df.sort_values(by='Date', ascending=False).head(10)\n",
    "\n",
    "# Show the most recent 10 movies and their ratings\n",
    "display(oliver_recent_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204bb3b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Set up BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Query to fetch the relevant data from BigQuery\n",
    "query = \"\"\"\n",
    "SELECT movieId, title\n",
    "FROM `film-wizard-453315.Grouplens.grouplens_movies`\n",
    "\"\"\"\n",
    "# Fetch data from BigQuery and load it into a DataFrame\n",
    "grouplens_movies_df = client.query(query).to_dataframe()\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "display('grouplens_movies_df:')\n",
    "display(grouplens_movies_df.head())\n",
    "\n",
    "# Perform fuzzy matching between 'title' in 'oliver_recent_movies' and 'title' in 'grouplens_movies_df'\n",
    "def get_best_match(title, choices, scorer=fuzz.ratio):\n",
    "    \"\"\"Fuzzy match using fuzz.ratio and return the best match.\"\"\"\n",
    "    match = process.extractOne(title, choices, scorer=scorer)\n",
    "    return match[0] if match else None\n",
    "\n",
    "# Apply fuzzy matching to the titles in 'oliver_recent_movies'\n",
    "oliver_recent_movies['matched_title'] = oliver_recent_movies['Name'].apply(\n",
    "    get_best_match, args=(grouplens_movies_df['title'],)\n",
    ")\n",
    "\n",
    "# Merge the original 'oliver_recent_movies' DataFrame with 'grouplens_movies_df' based on the 'matched_title'\n",
    "test_movies_with_ids = pd.merge(\n",
    "    oliver_recent_movies, \n",
    "    grouplens_movies_df[['title', 'movieId']], \n",
    "    left_on='matched_title', \n",
    "    right_on='title', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "##### Drop the 'matched_title' column and any other unnecessary columns - didn't use with Adam's csv\n",
    "# test_movies_with_ids = test_movies_with_ids.drop(columns=['matched_title', 'Letterboxd URI', 'title', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346fbc6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_movies_with_ids.drop_duplicates(inplace=True)\n",
    "\n",
    "# Show the final DataFrame\n",
    "display(test_movies_with_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c109099",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get all movie IDs in the GL dataset (this could be all movies in the system or a smaller list)\n",
    "all_movie_ids = full_gl_df['movieId'].unique()\n",
    "\n",
    "# Find unwatched movies for user 1 (exclude movies that user 1 has already rated)\n",
    "unwatched_movie_ids = [i for i in all_movie_ids if i not in test_movies_with_ids['movieId'].values]\n",
    "\n",
    "# Make predictions for the unwatched movies\n",
    "predictions = [best_algo.predict(1, movie_id) for movie_id in unwatched_movie_ids]\n",
    "\n",
    "# Sort the predictions by predicted rating (descending order)\n",
    "predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "# Extract top X recommended movies with their predicted ratings\n",
    "recommended_movies = [(pred.iid, pred.est) for pred in predictions[:10]]\n",
    "\n",
    "# Convert to DataFrame\n",
    "recommended_df = pd.DataFrame(recommended_movies, columns=[\"Movie ID\", \"Predicted Rating\"])\n",
    "display(recommended_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edde4d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display(recommended_df.info())\n",
    "display(grouplens_movies_df.info())\n",
    "\n",
    "# Bring back titles\n",
    "final_recommendation = pd.merge(\n",
    "    recommended_df, \n",
    "    grouplens_movies_df[['title', 'movieId']], \n",
    "    left_on='Movie ID', \n",
    "    right_on='movieId', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "final_recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af52cb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Understanding the Grouplens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa69832",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Pull table from bq\n",
    "sample_query = \"\"\"\n",
    "SELECT *\n",
    "FROM `film-wizard-453315.Grouplens.grouplens_movies`\n",
    "ORDER BY RAND()\n",
    "LIMIT 1000  -- Adjust for ~1% of 32M rows\n",
    "\"\"\"\n",
    "\n",
    "test_df = client.query(sample_query).to_dataframe()\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eb2ccc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('SVD_film_model.pkl', 'rb') as file:\n",
    "    best_algo_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adea233",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make predictions for the unwatched movies\n",
    "predictions = best_algo.predict(157707, 1)\n",
    "predictions\n",
    "\n",
    "# Sort the predictions by predicted rating (descending order)\n",
    "# predictions.sort(key=lambda x: x.est, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf7389",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69108055",
   "metadata": {},
   "source": [
    "## Online example of Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680fcc28",
   "metadata": {},
   "source": [
    "##### https://medium.com/@ckucewicz21/building-a-simple-movie-recommendation-system-with-surprise-6e61479e1e73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701afaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Load the MovieLens 100k dataset (this is built into Surprise)\n",
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c94936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and test set\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Create the SVD model and train it\n",
    "model = SVD()\n",
    "model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be010389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get top 5 recommendations for a user\n",
    "def get_top_n(predictions, n):\n",
    "    top_n = {}\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid not in top_n:\n",
    "            top_n[uid] = []\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Sort the predictions for each user and return the top n\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    \n",
    "    return top_n\n",
    "\n",
    "# Get predictions for the testset\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Get the top 5 recommendations for each user\n",
    "top_n = get_top_n(predictions, n=50)\n",
    "\n",
    "#-------------------------------\n",
    "\n",
    "# Get top recommendations for a specific user (e.g., user ID = 1)\n",
    "user_id = '825'\n",
    "user_top_n = top_n.get(user_id, [])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_user_top_825 = pd.DataFrame(user_top_n, columns=['Item ID', 'Estimated Rating'])\n",
    "\n",
    "# Get top recommendations for a specific user (e.g., user ID = 1)\n",
    "user_id = '253'\n",
    "user_top_n = top_n.get(user_id, [])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_user_top_253 = pd.DataFrame(user_top_n, columns=['Item ID', 'Estimated Rating'])\n",
    "\n",
    "# Find common Item IDs between the two DataFrames\n",
    "common_item_ids = df_user_top_825[df_user_top_825['Item ID'].isin(df_user_top_253['Item ID'])]\n",
    "\n",
    "# Display the common Item IDs\n",
    "display(common_item_ids)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df_user_top_825, df_user_top_253)\n",
    "\n",
    "# # Print the top 5 recommendations for a specific user (user_id = 1)\n",
    "# print(f\"Top 5 movie recommendations for user 825: {top_n.get('825')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d5a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e03671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top 5 recommendations for a specific user (user_id = 1)\n",
    "print(f\"Top 5 movie recommendations for user 622: {top_n.get('622')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
