{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "241180aa",
   "metadata": {},
   "source": [
    "## Final version - simplified SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eb6df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "print(\"Authenticated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a16182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from surprise.accuracy import rmse\n",
    "import pandas as pd\n",
    "\n",
    "# Define BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Define batch size & dataset properties\n",
    "BATCH_SIZE = 1_000_000  # 100k rows per batch\n",
    "TOTAL_ROWS = 32_000_000  # Approximate total dataset size\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "\n",
    "### **GL df**\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `film-wizard-453315.Grouplens.raw_grouplens_ratings`\n",
    "ORDER BY RAND()\n",
    "LIMIT 2000000\n",
    "\"\"\"\n",
    "\n",
    "# Fetch data from BigQuery\n",
    "gl_df = client.query(sample_query).to_dataframe()\n",
    "print(\"Loaded data from BigQuery:\", gl_df.shape)\n",
    "display(gl_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6841726",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ratings = pd.read_csv('/Users/oliverramsaygray/code/oliverramsaygray/film_wizard/raw_data/letterboxd-oliverramsay-2025-03-13-15-05-utc/new_user_ratings_v3.csv')\n",
    "new_user_ratings = new_user_ratings[new_user_ratings['Year'] <= 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d89f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up csv\n",
    "new_user_ratings.drop(columns=['Date', 'Year', 'Letterboxd URI'], inplace=True)\n",
    "new_user_ratings.dropna(inplace=True)\n",
    "new_user_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fuzzy matching ###\n",
    "### **GL df**\n",
    "sample_query = \"\"\"\n",
    "SELECT movieId, title\n",
    "FROM `film-wizard-453315.Grouplens.grouplens_movies`\n",
    "\"\"\"\n",
    "\n",
    "# Fetch data from BigQuery\n",
    "grouplens_movies = client.query(sample_query).to_dataframe()\n",
    "print(\"Loaded data from BigQuery:\", gl_df.shape)\n",
    "display(grouplens_movies.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76938898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "import pandas as pd\n",
    "\n",
    "def fuzzy_match(df1, col1, df2, col2, threshold=80):\n",
    "    matched_data = []\n",
    "    choices = df2[col2].tolist()  # Convert column to a list\n",
    "\n",
    "    for _, row in df1.iterrows():\n",
    "        name = row[col1]\n",
    "        rating = row['Rating']  # Retain 'Rating' column\n",
    "        result = process.extractOne(name, choices, scorer=fuzz.ratio)\n",
    "        \n",
    "        if result:  \n",
    "            match, score = result[:2]  # Extract match title and score\n",
    "            \n",
    "            if score >= threshold:\n",
    "                movie_id = df2.loc[df2[col2] == match, 'movieId'].values  # Get movieId\n",
    "                movie_id = movie_id[0] if len(movie_id) > 0 else None\n",
    "            else:\n",
    "                match, movie_id = None, None\n",
    "        else:\n",
    "            match, score, movie_id = None, 0, None\n",
    "\n",
    "        matched_data.append((name, rating, match, movie_id, score))\n",
    "\n",
    "    return pd.DataFrame(matched_data, columns=[col1, 'rating', 'Matched_Title', 'movieId', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d23058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "matches_df = fuzzy_match(new_user_ratings, 'Name', grouplens_movies, 'title')\n",
    "# matches_df = matches_df.rename(columns={'Rating': 'rating'})\n",
    "display(matches_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2ae032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max userId from gl_df and set it for all new rows\n",
    "new_user_id = gl_df['userId'].max() + 1\n",
    "matches_df['userId'] = new_user_id  # Assign new userId to all rows\n",
    "display(matches_df)\n",
    "display(gl_df)\n",
    "\n",
    "# # Append matches_df to gl_df\n",
    "gl_df = pd.concat([gl_df, matches_df[['userId', 'movieId', 'rating']]], ignore_index=True)\n",
    "\n",
    "display(gl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b2be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(gl_df, reader)\n",
    "\n",
    "# Split the data into a training and test set\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Create the SVD model and train it\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Define a function to get top 5 recommendations for a user\n",
    "def get_top_n(predictions, n):\n",
    "    top_n = {}\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid not in top_n:\n",
    "            top_n[uid] = []\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Sort the predictions for each user and return the top n\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    \n",
    "    return top_n\n",
    "\n",
    "# Load your data from BigQuery (assuming you have already loaded gl_df)\n",
    "# Here's an example:\n",
    "# gl_df = pd.read_csv('your_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **2️⃣ Cross-Validation Before Batch Training**\n",
    "cv_results = cross_validate(model, data, cv=5, verbose=True)\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a41ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movie_ids = grouplens_movies['movieId']\n",
    "all_movie_ids = all_movie_ids.unique()\n",
    "display(all_movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a8b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'all_movie_ids' and 'model' are already defined\n",
    "predictions_list = []\n",
    "\n",
    "# Loop through all movie IDs and make predictions\n",
    "for movieId in all_movie_ids:\n",
    "    prediction = model.predict(200949, movieId)\n",
    "    # Append the movieId and predicted rating (rename 'prediction' to 'estimated rating')\n",
    "    predictions_list.append({'movieId': movieId, 'estimated rating': prediction.est})\n",
    "\n",
    "# Create a DataFrame from the collected data with columns ['movieId', 'estimated rating']\n",
    "df_predictions = pd.DataFrame(predictions_list)\n",
    "\n",
    "df_predictions_sorted = df_predictions.sort_values(by='estimated rating', ascending=False)\n",
    "df_predictions_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = df_predictions_sorted.merge(grouplens_movies[['movieId', 'title']], on='movieId', how='inner')\n",
    "df_predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d9931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1685ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for the testset\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Get the top 10 recommendations for each user\n",
    "top_n = get_top_n(predictions, n=50)\n",
    "top_n.get(200949)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928e60e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming top_n.get(200949) returns a list of recommendations, e.g., [(movieId, rating), ...]\n",
    "recommendations = top_n.get(200949)\n",
    "\n",
    "# Convert the list of recommendations to a pandas DataFrame\n",
    "recommendations_df = pd.DataFrame(recommendations, columns=['movieId', 'Rating'])\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c46c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming grouplens_movies has columns ['movieId', 'title', ...]\n",
    "recommendations_with_titles = recommendations_df.merge(grouplens_movies[['movieId', 'title']], on='movieId', how='left')\n",
    "\n",
    "# Display the DataFrame with titles\n",
    "display(recommendations_with_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d79e73",
   "metadata": {},
   "source": [
    "#### Rough notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2005778",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\n",
    "    132721: [(3030, 4.343930472863401),\n",
    "  (3147, 4.173104100455896),\n",
    "  (8014, 4.10402787200236)],\n",
    " 134273: [(69481, 3.2115050041528552),\n",
    "  (2917, 3.147696080876573),\n",
    "  (1227, 3.14304677816368)],\n",
    " 163615: [(1196, 4.082660659362825),\n",
    "  (7099, 4.038083503624332),\n",
    "  (608, 3.769995671477647)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fffb20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert user recommendations into a single DataFrame\n",
    "data = []\n",
    "for user_id, movies in top_n.items():\n",
    "    for movie_id, rating in movies:\n",
    "        data.append((user_id, movie_id, rating))\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"userId\", \"movieId\", \"rating\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f99840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each movieId\n",
    "movie_counts = df['movieId'].value_counts()\n",
    "\n",
    "# Filter rows where movieId appears more than once\n",
    "duplicated_movies_df = df[df['movieId'].isin(movie_counts[movie_counts > 1].index)]\n",
    "\n",
    "print(duplicated_movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d44dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['movieId'] == 55820]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dbeddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {\n",
    "    'userId': [132721],\n",
    "    'movieId': [3030],\n",
    "    'rating': [4.343930472863401]\n",
    "}\n",
    "\n",
    "test_df = pd.DataFrame(data=test_dict)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8634703e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b785d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store DataFrames\n",
    "user_dfs = {}\n",
    "\n",
    "# Loop through each userId and create a DataFrame\n",
    "for user_id in top_n:\n",
    "    movie_data = top_n[user_id]  # Get movie list for the user\n",
    "    movie_ids = []\n",
    "    predicted_ratings = []\n",
    "    \n",
    "    # Extract movieId and predicted_rating\n",
    "    for movie in movie_data:\n",
    "        movie_ids.append(movie[0])\n",
    "        predicted_ratings.append(movie[1])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\"movieId\": movie_ids, \"predicted_rating\": predicted_ratings})\n",
    "    \n",
    "    # Store in dictionary\n",
    "    user_dfs[user_id] = df\n",
    "\n",
    "# Display example output\n",
    "for user_id in user_dfs:\n",
    "    print(f\"User {user_id} recommendations:\")\n",
    "    print(user_dfs[user_id], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af89d170",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SVD Grid Search User Review Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e0aa9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:10:16.772302Z",
     "start_time": "2025-03-13T11:10:16.721040Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "print(\"Authenticated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd541f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate, GridSearchCV\n",
    "from surprise.accuracy import rmse\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Define BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Define batch size & dataset properties\n",
    "BATCH_SIZE = 100_000  # 100k rows per batch\n",
    "TOTAL_ROWS = 500_000  # Approximate total dataset size\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "\n",
    "### **GL df with  500k randomly sampled ratings**\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `film-wizard-453315.Grouplens.500k_ratings`\n",
    "ORDER BY RAND()\n",
    "\"\"\"\n",
    "sample_gl_df = client.query(sample_query).to_dataframe()\n",
    "sample_gl_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a3121",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(sample_gl_df, reader)\n",
    "\n",
    "# Split the data into a training and test set\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Create the SVD model and train it\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Define a function to get top 5 recommendations for a user\n",
    "def get_top_n(predictions, n):\n",
    "    top_n = {}\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid not in top_n:\n",
    "            top_n[uid] = []\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Sort the predictions for each user and return the top n\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    \n",
    "    return top_n\n",
    "\n",
    "# **2️⃣ Cross-Validation Before Batch Training**\n",
    "cv_results = cross_validate(model, data, cv=5, verbose=True)\n",
    "print(cv_results)\n",
    "\n",
    "# Get predictions for the testset\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Get the top 5 recommendations for each user\n",
    "top_n = get_top_n(predictions, n=50)\n",
    "top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d64acb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "grouped_rating_df = sample_gl_df.groupby(by='movieId').count().sort_values(by='movieId', ascending=True)\n",
    "display(grouped_rating_df)\n",
    "\n",
    "# sns.histplot(data=grouped_rating_df, x='movieId')\n",
    "\n",
    "# sample_gl_df['quartile'] = pd.qcut(sample_gl_df['rating'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "# sample_gl_df\n",
    "\n",
    "# sample_gl_df.groupby(by='quartile').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd64cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouped_df = sample_gl_df.groupby('movieId').count().reset_index(names='num_reviews')\n",
    "grouped_df\n",
    "\n",
    "# grouped_df['quartile'] = pd.qcut(grouped_df['num_reviews'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "# group_df['quartile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b3620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### **1️⃣ Perform Grid Search on Small Sample**\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `film-wizard-453315.Grouplens.500k_ratings`\n",
    "ORDER BY RAND()\n",
    "LIMIT 100000  -- Adjust for ~20% of 500k rows\n",
    "\"\"\"\n",
    "grid_search_df = client.query(sample_query).to_dataframe()\n",
    "data = Dataset.load_from_df(grid_search_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    \"n_factors\": [10, 20, 50],  \n",
    "    \"reg_all\": [0.01, 0.03, 0.05]  \n",
    "}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\"], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "best_params = gs.best_params[\"rmse\"]\n",
    "print(\"Best Params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb2c819",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# **2️⃣ Cross-Validation Before Batch Training**\n",
    "best_algo = SVD(n_factors=best_params[\"n_factors\"], reg_all=best_params[\"reg_all\"])\n",
    "cv_results = cross_validate(best_algo, data, cv=5, verbose=True)\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8ff79f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# **3️⃣ Train on Full Dataset in Batches**\n",
    "for offset in range(0, TOTAL_ROWS, BATCH_SIZE):\n",
    "    batch_query = f\"\"\"\n",
    "    SELECT userId, movieId, rating\n",
    "    FROM `film-wizard-453315.Grouplens.500k_ratings`\n",
    "    ORDER BY userId\n",
    "    LIMIT {BATCH_SIZE} OFFSET {offset}\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_df = client.query(batch_query).to_dataframe()\n",
    "    \n",
    "    if batch_df.empty:\n",
    "        break  # Stop when there are no more rows\n",
    "    \n",
    "    dataset = Dataset.load_from_df(batch_df[['userId', 'movieId', 'rating']], reader)\n",
    "    trainset = dataset.build_full_trainset()\n",
    "    \n",
    "    best_algo.fit(trainset)\n",
    "    print(f\"✅ Processed {offset + BATCH_SIZE} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d47138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:11:20.420154Z",
     "start_time": "2025-03-13T11:11:10.122110Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### **4️⃣ Evaluate Best Model on a Fresh Test Set**\n",
    "test_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `film-wizard-453315.Grouplens.500k_ratings`\n",
    "ORDER BY RAND()\n",
    "LIMIT 1500000  -- Adjust for ~5% of 32M rows\n",
    "\"\"\"\n",
    "test_df = client.query(test_query).to_dataframe()\n",
    "testset = Dataset.load_from_df(test_df[['userId', 'movieId', 'rating']], reader).build_full_trainset().build_testset()\n",
    "\n",
    "predictions = best_algo.test(testset)\n",
    "print(\"Final RMSE on test set:\", rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221fa27c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "movieId_list = sample_gl_df['movieId']\n",
    "\n",
    "predictions_list = []\n",
    "\n",
    "for x in movieId_list:\n",
    "    predictions = best_algo.predict(2000, x)\n",
    "    predictions_list.append(predictions)\n",
    "    \n",
    "predictions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f88ee",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract movie IDs (iid) and predicted ratings (est)\n",
    "movie_ids = [pred.iid for pred in predictions_list]\n",
    "est_values = [pred.est for pred in predictions_list]\n",
    "\n",
    "# Plot the predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(movie_ids, est_values, alpha=0.5)\n",
    "plt.xlabel(\"Movie ID\")\n",
    "plt.ylabel(\"Predicted Rating (est)\")\n",
    "plt.title(\"Predicted Ratings for Each Movie\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b179c1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Lenskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f710a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from lenskit import crossfold\n",
    "from lenskit.als import BiasedMFScorer # https://lkpy.lenskit.org/stable/guide/gettingstarted\n",
    "from lenskit import util\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "print(\"Authenticated successfully!\")\n",
    "\n",
    "# Define batch size & dataset properties\n",
    "BATCH_SIZE = 100_000  # 100k rows per batch\n",
    "TOTAL_ROWS = 500_000  # Approximate total dataset size\n",
    "\n",
    "# Fetch 500k ratings from BigQuery randomly (for the entire dataset)\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM film-wizard-453315.Grouplens.500k_ratings\n",
    "ORDER BY RAND()\n",
    "\"\"\"\n",
    "sample_gl_df = client.query(sample_query).to_dataframe()\n",
    "\n",
    "# Rename columns to match LensKit's expected column names\n",
    "sample_gl_df = sample_gl_df.rename(columns={'userId': 'user_id', 'movieId': 'item_id'})\n",
    "sample_gl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf2491e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# I ned to define cv, hyperparam grid and then do a gridsearch\n",
    "\n",
    "# Train the model\n",
    "model = als.BiasedMF(features=3, reg=0.01, rng_spec=42)\n",
    "\n",
    "# Fit the model with your data\n",
    "model.fit(sample_gl_df[['user_id', 'item_id', 'rating']])\n",
    "\n",
    "# Create a scorer from the model\n",
    "scorer = model.scorer()\n",
    "\n",
    "# # ---------------------------\n",
    "\n",
    "# # Prepare data for training\n",
    "# train_data = sample_gl_df[['user', 'item', 'rating']]\n",
    "\n",
    "# # Define cross-validation with LensKit\n",
    "# folds = crossfold.sample_users(train_data, 5, size=0.2, method='random')  # 5-fold cross-validation\n",
    "\n",
    "# # Define a function for ALS model training\n",
    "# def train_als_model(train_data, factors=10, reg=0.01):\n",
    "#     algo = als.ALS(factors=factors, reg=reg, random_state=42)\n",
    "#     algo.fit(train_data)\n",
    "#     return algo\n",
    "\n",
    "# # Example hyperparameter grid (number of factors and regularization)\n",
    "# param_grid = {\n",
    "#     \"factors\": [5, 10, 50],\n",
    "#     \"reg\": [0.001, 0.01, 0.05]\n",
    "# }\n",
    "\n",
    "# # Manually grid search\n",
    "# best_rmse = float('inf')\n",
    "# best_params = {}\n",
    "\n",
    "# for factors in param_grid[\"factors\"]:\n",
    "#     for reg in param_grid[\"reg\"]:\n",
    "#         fold_rmse = []\n",
    "        \n",
    "#         for train, test in folds:\n",
    "#             model = train_als_model(train, factors=factors, reg=reg)\n",
    "            \n",
    "#             # Ensure the test data is in the form of a list of tuples (user, item)\n",
    "#             user_item_pairs = list(test[['user', 'item']].itertuples(index=False, name=None))\n",
    "            \n",
    "#             # Make predictions for these user-item pairs\n",
    "#             pred = model.predict(user_item_pairs)\n",
    "            \n",
    "#             # Calculate RMSE\n",
    "#             rmse_val = util.rmse(pred, test['rating'])\n",
    "#             fold_rmse.append(rmse_val)\n",
    "        \n",
    "#         mean_rmse = sum(fold_rmse) / len(fold_rmse)\n",
    "#         print(f\"Factors: {factors}, Reg: {reg}, RMSE: {mean_rmse}\")\n",
    "        \n",
    "#         if mean_rmse < best_rmse:\n",
    "#             best_rmse = mean_rmse\n",
    "#             best_params = {'factors': factors, 'reg': reg}\n",
    "\n",
    "# print(f\"Best Params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e5a0d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train the model using best hyperparameters from grid search\n",
    "best_algo = train_als_model(train_data, best_params['factors'], best_params['reg'])\n",
    "\n",
    "# Perform cross-validation to evaluate performance\n",
    "fold_rmse = []\n",
    "\n",
    "for train, test in folds:\n",
    "    model = train_als_model(train, best_params['factors'], best_params['reg'])\n",
    "    pred = model.predict(test[['userId', 'movieId']])\n",
    "    rmse_val = util.rmse(pred, test['rating'])\n",
    "    fold_rmse.append(rmse_val)\n",
    "\n",
    "print(f\"Cross-validation RMSE: {sum(fold_rmse)/len(fold_rmse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb542d63",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train on full dataset in batches\n",
    "for offset in range(0, TOTAL_ROWS, BATCH_SIZE):\n",
    "    batch_query = f\"\"\"\n",
    "    SELECT userId, movieId, rating\n",
    "    FROM film-wizard-453315.Grouplens.500k_ratings\n",
    "    ORDER BY userId\n",
    "    LIMIT {BATCH_SIZE} OFFSET {offset}\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_df = client.query(batch_query).to_dataframe()\n",
    "    \n",
    "    if batch_df.empty:\n",
    "        break  # Stop when there are no more rows\n",
    "    \n",
    "    train_data = batch_df[['userId', 'movieId', 'rating']]\n",
    "    \n",
    "    # Train the model on this batch\n",
    "    best_algo.fit(train_data)\n",
    "    print(f\"✅ Processed {offset + BATCH_SIZE} rows\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4286b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predict rating for a specific user and movie\n",
    "user_id = 10531\n",
    "movie_id = 100\n",
    "\n",
    "# Make prediction using the trained ALS model\n",
    "prediction = best_algo.predict(user_id, movie_id)\n",
    "print(f\"Predicted rating for user {user_id} and movie {movie_id}: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fffea9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Notes from original SVD jn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105bd81",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Path to your CSV file\n",
    "csv_path = \"/Users/oliverramsaygray/code/oliverramsaygray/film_wizard/raw_data/Adam films/9a884b4e-8993-4800-925a-bea11dcce39e.csv\"\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "movies_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Convert the 'date' column to datetime if it's not already\n",
    "movies_df['Date'] = pd.to_datetime(movies_df['Date'])\n",
    "\n",
    "# Filter out movies released in or after October 2023\n",
    "movies_df = movies_df[movies_df['Date'] < '2023-10-01']\n",
    "\n",
    "#Filter out movies that Grouplens later has an issue matching with\n",
    "# Exclude specific movies by title\n",
    "movies_to_exclude = [\"Herod's Law\", \"Spirited Away\", \"Sing\", \"Living\", \"Fury\"]  # Replace with actual movie titles\n",
    "movies_df = movies_df[~movies_df['Name'].isin(movies_to_exclude)]\n",
    "\n",
    "##### Half the ratings to be out of 5 - only for Adam #####\n",
    "movies_df['Rating'] = movies_df['Rating']/2\n",
    "\n",
    "# Sort by 'date' in descending order to get the most recent entries\n",
    "oliver_recent_movies = movies_df.sort_values(by='Date', ascending=False).head(10)\n",
    "\n",
    "# Show the most recent 10 movies and their ratings\n",
    "display(oliver_recent_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204bb3b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Set up BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Query to fetch the relevant data from BigQuery\n",
    "query = \"\"\"\n",
    "SELECT movieId, title\n",
    "FROM `film-wizard-453315.Grouplens.grouplens_movies`\n",
    "\"\"\"\n",
    "# Fetch data from BigQuery and load it into a DataFrame\n",
    "grouplens_movies_df = client.query(query).to_dataframe()\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "display('grouplens_movies_df:')\n",
    "display(grouplens_movies_df.head())\n",
    "\n",
    "# Perform fuzzy matching between 'title' in 'oliver_recent_movies' and 'title' in 'grouplens_movies_df'\n",
    "def get_best_match(title, choices, scorer=fuzz.ratio):\n",
    "    \"\"\"Fuzzy match using fuzz.ratio and return the best match.\"\"\"\n",
    "    match = process.extractOne(title, choices, scorer=scorer)\n",
    "    return match[0] if match else None\n",
    "\n",
    "# Apply fuzzy matching to the titles in 'oliver_recent_movies'\n",
    "oliver_recent_movies['matched_title'] = oliver_recent_movies['Name'].apply(\n",
    "    get_best_match, args=(grouplens_movies_df['title'],)\n",
    ")\n",
    "\n",
    "# Merge the original 'oliver_recent_movies' DataFrame with 'grouplens_movies_df' based on the 'matched_title'\n",
    "test_movies_with_ids = pd.merge(\n",
    "    oliver_recent_movies, \n",
    "    grouplens_movies_df[['title', 'movieId']], \n",
    "    left_on='matched_title', \n",
    "    right_on='title', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "##### Drop the 'matched_title' column and any other unnecessary columns - didn't use with Adam's csv\n",
    "# test_movies_with_ids = test_movies_with_ids.drop(columns=['matched_title', 'Letterboxd URI', 'title', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346fbc6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_movies_with_ids.drop_duplicates(inplace=True)\n",
    "\n",
    "# Show the final DataFrame\n",
    "display(test_movies_with_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c109099",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get all movie IDs in the GL dataset (this could be all movies in the system or a smaller list)\n",
    "all_movie_ids = full_gl_df['movieId'].unique()\n",
    "\n",
    "# Find unwatched movies for user 1 (exclude movies that user 1 has already rated)\n",
    "unwatched_movie_ids = [i for i in all_movie_ids if i not in test_movies_with_ids['movieId'].values]\n",
    "\n",
    "# Make predictions for the unwatched movies\n",
    "predictions = [best_algo.predict(1, movie_id) for movie_id in unwatched_movie_ids]\n",
    "\n",
    "# Sort the predictions by predicted rating (descending order)\n",
    "predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "# Extract top X recommended movies with their predicted ratings\n",
    "recommended_movies = [(pred.iid, pred.est) for pred in predictions[:10]]\n",
    "\n",
    "# Convert to DataFrame\n",
    "recommended_df = pd.DataFrame(recommended_movies, columns=[\"Movie ID\", \"Predicted Rating\"])\n",
    "display(recommended_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edde4d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display(recommended_df.info())\n",
    "display(grouplens_movies_df.info())\n",
    "\n",
    "# Bring back titles\n",
    "final_recommendation = pd.merge(\n",
    "    recommended_df, \n",
    "    grouplens_movies_df[['title', 'movieId']], \n",
    "    left_on='Movie ID', \n",
    "    right_on='movieId', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "final_recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af52cb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Understanding the Grouplens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa69832",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Pull table from bq\n",
    "sample_query = \"\"\"\n",
    "SELECT *\n",
    "FROM `film-wizard-453315.Grouplens.grouplens_movies`\n",
    "ORDER BY RAND()\n",
    "LIMIT 1000  -- Adjust for ~1% of 32M rows\n",
    "\"\"\"\n",
    "\n",
    "test_df = client.query(sample_query).to_dataframe()\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eb2ccc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('SVD_film_model.pkl', 'rb') as file:\n",
    "    best_algo_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adea233",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make predictions for the unwatched movies\n",
    "predictions = best_algo.predict(157707, 1)\n",
    "predictions\n",
    "\n",
    "# Sort the predictions by predicted rating (descending order)\n",
    "# predictions.sort(key=lambda x: x.est, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf7389",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69108055",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Online example of Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680fcc28",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### https://medium.com/@ckucewicz21/building-a-simple-movie-recommendation-system-with-surprise-6e61479e1e73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701afaed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Load the MovieLens 100k dataset (this is built into Surprise)\n",
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c94936",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split the data into a training and test set\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Create the SVD model and train it\n",
    "model = SVD()\n",
    "model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be010389",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define a function to get top 5 recommendations for a user\n",
    "def get_top_n(predictions, n):\n",
    "    top_n = {}\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid not in top_n:\n",
    "            top_n[uid] = []\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Sort the predictions for each user and return the top n\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    \n",
    "    return top_n\n",
    "\n",
    "# Get predictions for the testset\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Get the top 5 recommendations for each user\n",
    "top_n = get_top_n(predictions, n=50)\n",
    "\n",
    "#-------------------------------\n",
    "\n",
    "# Get top recommendations for a specific user (e.g., user ID = 1)\n",
    "user_id = '825'\n",
    "user_top_n = top_n.get(user_id, [])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_user_top_825 = pd.DataFrame(user_top_n, columns=['Item ID', 'Estimated Rating'])\n",
    "\n",
    "# Get top recommendations for a specific user (e.g., user ID = 1)\n",
    "user_id = '253'\n",
    "user_top_n = top_n.get(user_id, [])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_user_top_253 = pd.DataFrame(user_top_n, columns=['Item ID', 'Estimated Rating'])\n",
    "\n",
    "# Find common Item IDs between the two DataFrames\n",
    "common_item_ids = df_user_top_825[df_user_top_825['Item ID'].isin(df_user_top_253['Item ID'])]\n",
    "\n",
    "# Display the common Item IDs\n",
    "display(common_item_ids)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df_user_top_825, df_user_top_253)\n",
    "\n",
    "# # Print the top 5 recommendations for a specific user (user_id = 1)\n",
    "# print(f\"Top 5 movie recommendations for user 825: {top_n.get('825')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d5a5c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e03671",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Print the top 5 recommendations for a specific user (user_id = 1)\n",
    "print(f\"Top 5 movie recommendations for user 622: {top_n.get('622')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
