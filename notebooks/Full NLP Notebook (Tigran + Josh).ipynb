{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c9e83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers torch pytesseract\n",
    "# !pip install sentencepiece sacremoses\n",
    "# !brew install xz\n",
    "#import _lzma\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e6da26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barbarosa (1982)</td>\n",
       "      <td>1982</td>\n",
       "      <td>DAMN, WHERE ARE WE?\\n WHEW, WE GOTTA FIND SOME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chestnut (2023)</td>\n",
       "      <td>2023</td>\n",
       "      <td>1\\n [ Birds chirping in distance ]\\n [ Phone r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Contractor, The (2007)</td>\n",
       "      <td>2007</td>\n",
       "      <td>Ah, James.\\n Ali Mahmud Jahar.\\n Remember him?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>George Michael: Freedom Uncut (2022)</td>\n",
       "      <td>2022</td>\n",
       "      <td>On Christmas Day, 2016,\\n we heard with shock\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Objective, Burma! (1945)</td>\n",
       "      <td>1945</td>\n",
       "      <td>This is Burma...\\n the toughest battleground i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Out on a Limb (1992)</td>\n",
       "      <td>1992</td>\n",
       "      <td>MISS CLAYTON: Okay,\\n find a seat. Sit down, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Piranha (2010)</td>\n",
       "      <td>2010</td>\n",
       "      <td>Oh... boy...\\n That's a fast fish.\\n C'mon... ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Scoop (2006)</td>\n",
       "      <td>2006</td>\n",
       "      <td>Don't mourn for Joe Strombel.\\n Joe Strombel l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Secret of the Incas (1954)</td>\n",
       "      <td>1954</td>\n",
       "      <td>1\\n (dramatic music)\\n (flute music)\\n (singer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Slumber Party Massacre II (1987)</td>\n",
       "      <td>1987</td>\n",
       "      <td>Dr. Weiss says\\n that it's perfectly normal\\n ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title  Year  \\\n",
       "0                      Barbarosa (1982)  1982   \n",
       "1                       Chestnut (2023)  2023   \n",
       "2                Contractor, The (2007)  2007   \n",
       "3  George Michael: Freedom Uncut (2022)  2022   \n",
       "4              Objective, Burma! (1945)  1945   \n",
       "5                  Out on a Limb (1992)  1992   \n",
       "6                        Piranha (2010)  2010   \n",
       "7                          Scoop (2006)  2006   \n",
       "8            Secret of the Incas (1954)  1954   \n",
       "9      Slumber Party Massacre II (1987)  1987   \n",
       "\n",
       "                                              Script  \n",
       "0  DAMN, WHERE ARE WE?\\n WHEW, WE GOTTA FIND SOME...  \n",
       "1  1\\n [ Birds chirping in distance ]\\n [ Phone r...  \n",
       "2  Ah, James.\\n Ali Mahmud Jahar.\\n Remember him?...  \n",
       "3  On Christmas Day, 2016,\\n we heard with shock\\...  \n",
       "4  This is Burma...\\n the toughest battleground i...  \n",
       "5  MISS CLAYTON: Okay,\\n find a seat. Sit down, p...  \n",
       "6  Oh... boy...\\n That's a fast fish.\\n C'mon... ...  \n",
       "7  Don't mourn for Joe Strombel.\\n Joe Strombel l...  \n",
       "8  1\\n (dramatic music)\\n (flute music)\\n (singer...  \n",
       "9  Dr. Weiss says\\n that it's perfectly normal\\n ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "# Correct bucket name and file path\n",
    "bucket_name = \"springfield_40k\"  # Ensure this matches your actual bucket name\n",
    "css_file_path = \"springfield_10_scripts.csv\"  # Use only the relative path, not the full URL\n",
    "css_file_path_full = \"springfield_40k_movie_scripts.csv\"  # Use only the relative path, not the full URL\n",
    "\n",
    "# Initialize GCS client\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(bucket_name)\n",
    "blob = bucket.blob(css_file_path)\n",
    "\n",
    "# Read the CSS content (or CSV in this case)\n",
    "df = pd.read_csv(blob.open('r'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e2b901-6d14-4053-8610-27bc69fc7c4c",
   "metadata": {},
   "source": [
    "# Josh Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb2c3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(script):\n",
    "    '''\n",
    "    Function that takes raw script and cleans it.\n",
    "    Returns list of individual words.\n",
    "    Example: \n",
    "    Input: 'Hello, my... name is!'\n",
    "    Output: ['hello','my','name','is']\n",
    "    '''\n",
    "    # Remove punctuation.\n",
    "    for punctuation in string.punctuation:\n",
    "        script = script.replace(punctuation, \"\")\n",
    "    # Split on whitespace to isolate words\n",
    "    script_split = script.split(\" \")\n",
    "    # Removing \"words\" that are just numbers, i.e. have no letters\n",
    "    script_words = [word for word in script_split if any(c.isalpha() for c in word)]\n",
    "    # Remove new lines, \\n isn't removed by punctuation above.\n",
    "    words_stripped = [word.strip() for word in script_words]\n",
    "    # Lowercase in order to count occurances of same word.\n",
    "    words_clean = [word.lower() for word in words_stripped]\n",
    "    return words_clean\n",
    "    \n",
    "def count_hapax(words_clean):\n",
    "    ''' \n",
    "    Function to count number of hapax legomenon, i.e.\n",
    "    words that appear once in a corpus/text.\n",
    "    '''\n",
    "    #words_clean = clean_words(script)\n",
    "    word_counts = Counter(words_clean)\n",
    "    # Hapax Legomenon counter\n",
    "    hell = 0\n",
    "    for word in word_counts.keys():\n",
    "        if word_counts[word] == 1:\n",
    "            hell += 1\n",
    "    return {'hapax': hell}\n",
    "\n",
    "def readability_metrics(script):\n",
    "    '''\n",
    "    Function that calculates the readability of a script.\n",
    "    '''\n",
    "    # Cleaning is done differently here so that the input to the textstat\n",
    "    # metric functions is correct. Essentially it wants to keep punctuation.\n",
    "    \n",
    "    # Split on whitespace to isolate words\n",
    "    script_split = script.split(\" \")\n",
    "    # Removing \"words\" that are just numbers, i.e. have no letters\n",
    "    script_words = [word for word in script_split if any(c.isalpha() for c in word)]\n",
    "    # Remove new lines\n",
    "    words_stripped = [word.strip() for word in script_words]\n",
    "    words_clean = words_stripped\n",
    "    \n",
    "    text = \" \".join(words_clean)\n",
    "    # Flesch-Kincaid Grade Level - measures US Grade level required to read text.\n",
    "    fkgl = textstat.flesch_kincaid_grade(text)\n",
    "    # Flesch Reading Ease - overall score\n",
    "    fre = textstat.flesch_reading_ease(text)\n",
    "    # SMOG Test - better for jargon/technical text\n",
    "    smog = textstat.smog_index(text)\n",
    "    # Gunning Fog Index - complexity of sentence structure and vocab\n",
    "    fog = textstat.gunning_fog(text)\n",
    "\n",
    "    return {'fkgl': fkgl, 'fre': fre, 'smog': smog, 'fog': fog}\n",
    "\n",
    "def vocab_size(words_clean):\n",
    "    ''' \n",
    "    Function to count number of unique words.\n",
    "    '''\n",
    "    \n",
    "    #words_clean = clean_words(script)\n",
    "    word_counts = Counter(words_clean)\n",
    "    \n",
    "    return {'word count': len(word_counts)}\n",
    "\n",
    "def type_token_ratio(words_clean):\n",
    "    ''' \n",
    "    Function to calculate the type token ratio.\n",
    "    TTR = (# unique words)/(total # words)\n",
    "    '''\n",
    "    \n",
    "    #words_clean = clean_words(script)\n",
    "    word_counts = Counter(words_clean)\n",
    "    \n",
    "    return {'TTR': len(word_counts)/len(words_clean)}\n",
    "\n",
    "def script_length(words_clean):\n",
    "    ''' \n",
    "    Function to calculate the script length.\n",
    "    '''\n",
    "    \n",
    "    #words_clean = clean_words(script)\n",
    "    \n",
    "    return {'script_length': len(words_clean)}\n",
    "\n",
    "def mean_word_length(words_clean):\n",
    "    ''' \n",
    "    Function to find the mean word length in a script.\n",
    "    '''\n",
    "    \n",
    "    #words_clean = clean_words(script)\n",
    "    word_lengths = np.array([len(word) for word in words_clean],dtype='int')\n",
    "    return {'mean_word_length': np.mean(word_lengths)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d432d167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "55e1f6d7-207b-493e-8570-5282f86f1088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Script</th>\n",
       "      <th>Clean Script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barbarosa (1982)</td>\n",
       "      <td>1982</td>\n",
       "      <td>DAMN, WHERE ARE WE?\\n WHEW, WE GOTTA FIND SOME...</td>\n",
       "      <td>[damn, where, are, we, whew, we, gotta, find, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chestnut (2023)</td>\n",
       "      <td>2023</td>\n",
       "      <td>1\\n [ Birds chirping in distance ]\\n [ Phone r...</td>\n",
       "      <td>[birds, chirping, in, distance, phone, ringing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Contractor, The (2007)</td>\n",
       "      <td>2007</td>\n",
       "      <td>Ah, James.\\n Ali Mahmud Jahar.\\n Remember him?...</td>\n",
       "      <td>[ah, james, ali, mahmud, jahar, remember, him,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>George Michael: Freedom Uncut (2022)</td>\n",
       "      <td>2022</td>\n",
       "      <td>On Christmas Day, 2016,\\n we heard with shock\\...</td>\n",
       "      <td>[on, christmas, day, we, heard, with, shock, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Objective, Burma! (1945)</td>\n",
       "      <td>1945</td>\n",
       "      <td>This is Burma...\\n the toughest battleground i...</td>\n",
       "      <td>[this, is, burma, the, toughest, battleground,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Out on a Limb (1992)</td>\n",
       "      <td>1992</td>\n",
       "      <td>MISS CLAYTON: Okay,\\n find a seat. Sit down, p...</td>\n",
       "      <td>[miss, clayton, okay, find, a, seat, sit, down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Piranha (2010)</td>\n",
       "      <td>2010</td>\n",
       "      <td>Oh... boy...\\n That's a fast fish.\\n C'mon... ...</td>\n",
       "      <td>[oh, boy, thats, a, fast, fish, cmon, cmon, cm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Scoop (2006)</td>\n",
       "      <td>2006</td>\n",
       "      <td>Don't mourn for Joe Strombel.\\n Joe Strombel l...</td>\n",
       "      <td>[dont, mourn, for, joe, strombel, joe, strombe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Secret of the Incas (1954)</td>\n",
       "      <td>1954</td>\n",
       "      <td>1\\n (dramatic music)\\n (flute music)\\n (singer...</td>\n",
       "      <td>[dramatic, music, flute, music, singer, vocali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Slumber Party Massacre II (1987)</td>\n",
       "      <td>1987</td>\n",
       "      <td>Dr. Weiss says\\n that it's perfectly normal\\n ...</td>\n",
       "      <td>[dr, weiss, says, that, its, perfectly, normal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title  Year  \\\n",
       "0                      Barbarosa (1982)  1982   \n",
       "1                       Chestnut (2023)  2023   \n",
       "2                Contractor, The (2007)  2007   \n",
       "3  George Michael: Freedom Uncut (2022)  2022   \n",
       "4              Objective, Burma! (1945)  1945   \n",
       "5                  Out on a Limb (1992)  1992   \n",
       "6                        Piranha (2010)  2010   \n",
       "7                          Scoop (2006)  2006   \n",
       "8            Secret of the Incas (1954)  1954   \n",
       "9      Slumber Party Massacre II (1987)  1987   \n",
       "\n",
       "                                              Script  \\\n",
       "0  DAMN, WHERE ARE WE?\\n WHEW, WE GOTTA FIND SOME...   \n",
       "1  1\\n [ Birds chirping in distance ]\\n [ Phone r...   \n",
       "2  Ah, James.\\n Ali Mahmud Jahar.\\n Remember him?...   \n",
       "3  On Christmas Day, 2016,\\n we heard with shock\\...   \n",
       "4  This is Burma...\\n the toughest battleground i...   \n",
       "5  MISS CLAYTON: Okay,\\n find a seat. Sit down, p...   \n",
       "6  Oh... boy...\\n That's a fast fish.\\n C'mon... ...   \n",
       "7  Don't mourn for Joe Strombel.\\n Joe Strombel l...   \n",
       "8  1\\n (dramatic music)\\n (flute music)\\n (singer...   \n",
       "9  Dr. Weiss says\\n that it's perfectly normal\\n ...   \n",
       "\n",
       "                                        Clean Script  \n",
       "0  [damn, where, are, we, whew, we, gotta, find, ...  \n",
       "1  [birds, chirping, in, distance, phone, ringing...  \n",
       "2  [ah, james, ali, mahmud, jahar, remember, him,...  \n",
       "3  [on, christmas, day, we, heard, with, shock, a...  \n",
       "4  [this, is, burma, the, toughest, battleground,...  \n",
       "5  [miss, clayton, okay, find, a, seat, sit, down...  \n",
       "6  [oh, boy, thats, a, fast, fish, cmon, cmon, cm...  \n",
       "7  [dont, mourn, for, joe, strombel, joe, strombe...  \n",
       "8  [dramatic, music, flute, music, singer, vocali...  \n",
       "9  [dr, weiss, says, that, its, perfectly, normal...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Clean Script\"] = df[\"Script\"].apply(clean_words)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ec13bc65-1691-476e-b251-ff626b9fb5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at j-hartmann/emotion-english-distilroberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "sentiment_pipe = pipeline('sentiment-analysis', model='cardiffnlp/twitter-roberta-base-sentiment')\n",
    "emotion_pipe = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f91f05ae-149e-4816-b89c-3cea52bd6954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_script(script, max_chars=600):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "\n",
    "    while start < len(script):\n",
    "        # Find the nearest newline after 400 characters\n",
    "        end = start + max_chars\n",
    "        if end < len(script):\n",
    "            newline_pos = script.rfind(\"\\n\", start, end)\n",
    "            if newline_pos != -1:\n",
    "                end = newline_pos + 1  # Include the newline\n",
    "        chunks.append(script[start:end].strip().replace('\\n',' '))  # Add chunk, remove leading/trailing spaces\n",
    "        start = end  # Move to the next chunk\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def sentiment_params(script):\n",
    "    sentiments = []\n",
    "    chunks = split_script(script)\n",
    "\n",
    "    # Define mapping dictionary\n",
    "    sentiment_mapping = {\n",
    "        '0': -1,  # Negative\n",
    "        '1': 0,   # Neutral\n",
    "        '2': 1    # Positive\n",
    "    }\n",
    "\n",
    "    for chunk in chunks:\n",
    "        sentiment_label = sentiment_pipe(chunk)[0]['label']\n",
    "        sentiment = sentiment_mapping.get(sentiment_label[-1], 0)  # Default to 0 if not found\n",
    "        sentiments.append(sentiment)\n",
    "\n",
    "    #sentiments ready\n",
    "\n",
    "    #2 Entropy\n",
    "    count_pos = sentiments.count(1)\n",
    "    count_neg = sentiments.count(-1)\n",
    "    count3_neut = sentiments.count(0)\n",
    "    #print(count_pos, count_neg, count3_neut)\n",
    "    prob_pos, prob_neg, prob_neut= count_pos/len(sentiments), count_neg/len(sentiments), count3_neut/len(sentiments)\n",
    "\n",
    "    sentiment_entropy = -(prob_pos * np.log2(prob_pos) + prob_neg * np.log2(prob_neg) + prob_neut * np.log2(prob_neut))\n",
    "\n",
    "    #3 Std of sentiment\n",
    "    sentiment_diff = np.array(sentiments[1:]) - np.array(sentiments[:-1])\n",
    "    sentiment_std = np.std(sentiment_diff)\n",
    "\n",
    "    return {'sentiment_entropy': sentiment_entropy, 'sentiment_std': sentiment_std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "40d16e6c-14dc-4f69-a984-385dd152cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_frequencies(script):\n",
    "    emotions = []\n",
    "    chunks = split_script(script)\n",
    "    for chunk in chunks:\n",
    "        emot = emotion_pipe(chunk)[0]['label']\n",
    "        emotions.append(emot)\n",
    "\n",
    "    # Count occurrences\n",
    "    counts = Counter(emotions)\n",
    "\n",
    "    # Total number of occurrences (for normalization)\n",
    "    total_count = sum(counts.values())\n",
    "\n",
    "    # Normalize frequencies\n",
    "    normalized_frequencies = {emotion: freq / total_count for emotion, freq in counts.items()}\n",
    "\n",
    "    return normalized_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "60c7e83f-fb63-4d44-a690-427fa9a1fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedder(df): \n",
    "    #clean script for processing\n",
    "    df[\"Clean_Script\"] = df[\"Script\"].apply(clean_words)\n",
    "    #emotions\n",
    "    df_emotions = df[\"Script\"].apply(emotion_frequencies).apply(pd.Series)\n",
    "    #sentiments\n",
    "    df_sentiments = df[\"Script\"].apply(sentiment_params).apply(pd.Series)\n",
    "    #complexity\n",
    "    df_hapax = df[\"Clean_Script\"].apply(count_hapax).apply(pd.Series)\n",
    "    df_readability = df[\"Script\"].apply(readability_metrics).apply(pd.Series)\n",
    "    df_voc = df[\"Clean_Script\"].apply(vocab_size).apply(pd.Series)\n",
    "    df_ttr = df[\"Clean_Script\"].apply(type_token_ratio).apply(pd.Series)\n",
    "    df_scr = df[\"Clean_Script\"].apply(script_length).apply(pd.Series)\n",
    "    df_mwl = df[\"Clean_Script\"].apply(mean_word_length).apply(pd.Series)\n",
    "    # Merge new features into original DataFrame\n",
    "    \n",
    "    df_embedded = pd.concat([df, \n",
    "                             df_emotions, \n",
    "                             df_sentiments,\n",
    "                             df_hapax,\n",
    "                             df_readability,\n",
    "                             df_voc,\n",
    "                             df_ttr,\n",
    "                             df_scr,\n",
    "                             df_mwl\n",
    "                            ],\n",
    "                            axis=1)\n",
    "\n",
    "    # Show result\n",
    "    return df_embedded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "565204e4-63ea-4899-a207-523d17c54bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 31s, sys: 1min 26s, total: 12min 58s\n",
      "Wall time: 3min 37s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Script</th>\n",
       "      <th>Clean Script</th>\n",
       "      <th>Clean_Script</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>joy</th>\n",
       "      <th>...</th>\n",
       "      <th>sentiment_std</th>\n",
       "      <th>hapax</th>\n",
       "      <th>fkgl</th>\n",
       "      <th>fre</th>\n",
       "      <th>smog</th>\n",
       "      <th>fog</th>\n",
       "      <th>word count</th>\n",
       "      <th>TTR</th>\n",
       "      <th>script_length</th>\n",
       "      <th>mean_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barbarosa (1982)</td>\n",
       "      <td>1982</td>\n",
       "      <td>DAMN, WHERE ARE WE?\\n WHEW, WE GOTTA FIND SOME...</td>\n",
       "      <td>[damn, where, are, we, whew, we, gotta, find, ...</td>\n",
       "      <td>[damn, where, are, we, whew, we, gotta, find, ...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722642</td>\n",
       "      <td>482</td>\n",
       "      <td>1.3</td>\n",
       "      <td>98.21</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.31</td>\n",
       "      <td>949</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>4672</td>\n",
       "      <td>3.858305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chestnut (2023)</td>\n",
       "      <td>2023</td>\n",
       "      <td>1\\n [ Birds chirping in distance ]\\n [ Phone r...</td>\n",
       "      <td>[birds, chirping, in, distance, phone, ringing...</td>\n",
       "      <td>[birds, chirping, in, distance, phone, ringing...</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.287879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936315</td>\n",
       "      <td>453</td>\n",
       "      <td>2.9</td>\n",
       "      <td>88.63</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.75</td>\n",
       "      <td>988</td>\n",
       "      <td>0.149245</td>\n",
       "      <td>6620</td>\n",
       "      <td>3.939275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Contractor, The (2007)</td>\n",
       "      <td>2007</td>\n",
       "      <td>Ah, James.\\n Ali Mahmud Jahar.\\n Remember him?...</td>\n",
       "      <td>[ah, james, ali, mahmud, jahar, remember, him,...</td>\n",
       "      <td>[ah, james, ali, mahmud, jahar, remember, him,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741620</td>\n",
       "      <td>536</td>\n",
       "      <td>3.6</td>\n",
       "      <td>81.49</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.41</td>\n",
       "      <td>952</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>4046</td>\n",
       "      <td>4.260257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>George Michael: Freedom Uncut (2022)</td>\n",
       "      <td>2022</td>\n",
       "      <td>On Christmas Day, 2016,\\n we heard with shock\\...</td>\n",
       "      <td>[on, christmas, day, we, heard, with, shock, a...</td>\n",
       "      <td>[on, christmas, day, we, heard, with, shock, a...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.150794</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995992</td>\n",
       "      <td>1090</td>\n",
       "      <td>5.5</td>\n",
       "      <td>81.93</td>\n",
       "      <td>8.6</td>\n",
       "      <td>6.96</td>\n",
       "      <td>2043</td>\n",
       "      <td>0.151580</td>\n",
       "      <td>13478</td>\n",
       "      <td>4.016471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Objective, Burma! (1945)</td>\n",
       "      <td>1945</td>\n",
       "      <td>This is Burma...\\n the toughest battleground i...</td>\n",
       "      <td>[this, is, burma, the, toughest, battleground,...</td>\n",
       "      <td>[this, is, burma, the, toughest, battleground,...</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806599</td>\n",
       "      <td>801</td>\n",
       "      <td>2.4</td>\n",
       "      <td>89.85</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1579</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>8650</td>\n",
       "      <td>3.998613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Out on a Limb (1992)</td>\n",
       "      <td>1992</td>\n",
       "      <td>MISS CLAYTON: Okay,\\n find a seat. Sit down, p...</td>\n",
       "      <td>[miss, clayton, okay, find, a, seat, sit, down...</td>\n",
       "      <td>[miss, clayton, okay, find, a, seat, sit, down...</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.301587</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782881</td>\n",
       "      <td>634</td>\n",
       "      <td>2.6</td>\n",
       "      <td>89.55</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.67</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.196112</td>\n",
       "      <td>6379</td>\n",
       "      <td>3.994670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Piranha (2010)</td>\n",
       "      <td>2010</td>\n",
       "      <td>Oh... boy...\\n That's a fast fish.\\n C'mon... ...</td>\n",
       "      <td>[oh, boy, thats, a, fast, fish, cmon, cmon, cm...</td>\n",
       "      <td>[oh, boy, thats, a, fast, fish, cmon, cmon, cm...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.160577</td>\n",
       "      <td>564</td>\n",
       "      <td>2.2</td>\n",
       "      <td>90.36</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.46</td>\n",
       "      <td>1041</td>\n",
       "      <td>0.203281</td>\n",
       "      <td>5121</td>\n",
       "      <td>3.932630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Scoop (2006)</td>\n",
       "      <td>2006</td>\n",
       "      <td>Don't mourn for Joe Strombel.\\n Joe Strombel l...</td>\n",
       "      <td>[dont, mourn, for, joe, strombel, joe, strombe...</td>\n",
       "      <td>[dont, mourn, for, joe, strombel, joe, strombe...</td>\n",
       "      <td>0.264463</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.280992</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.165289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908257</td>\n",
       "      <td>1047</td>\n",
       "      <td>2.7</td>\n",
       "      <td>89.14</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.23</td>\n",
       "      <td>1935</td>\n",
       "      <td>0.153219</td>\n",
       "      <td>12629</td>\n",
       "      <td>3.991290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Secret of the Incas (1954)</td>\n",
       "      <td>1954</td>\n",
       "      <td>1\\n (dramatic music)\\n (flute music)\\n (singer...</td>\n",
       "      <td>[dramatic, music, flute, music, singer, vocali...</td>\n",
       "      <td>[dramatic, music, flute, music, singer, vocali...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.287500</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746299</td>\n",
       "      <td>714</td>\n",
       "      <td>2.6</td>\n",
       "      <td>89.34</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1405</td>\n",
       "      <td>0.175933</td>\n",
       "      <td>7986</td>\n",
       "      <td>4.086026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Slumber Party Massacre II (1987)</td>\n",
       "      <td>1987</td>\n",
       "      <td>Dr. Weiss says\\n that it's perfectly normal\\n ...</td>\n",
       "      <td>[dr, weiss, says, that, its, perfectly, normal...</td>\n",
       "      <td>[dr, weiss, says, that, its, perfectly, normal...</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>...</td>\n",
       "      <td>1.136515</td>\n",
       "      <td>457</td>\n",
       "      <td>2.2</td>\n",
       "      <td>95.98</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.13</td>\n",
       "      <td>954</td>\n",
       "      <td>0.181853</td>\n",
       "      <td>5246</td>\n",
       "      <td>3.773351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title  Year  \\\n",
       "0                      Barbarosa (1982)  1982   \n",
       "1                       Chestnut (2023)  2023   \n",
       "2                Contractor, The (2007)  2007   \n",
       "3  George Michael: Freedom Uncut (2022)  2022   \n",
       "4              Objective, Burma! (1945)  1945   \n",
       "5                  Out on a Limb (1992)  1992   \n",
       "6                        Piranha (2010)  2010   \n",
       "7                          Scoop (2006)  2006   \n",
       "8            Secret of the Incas (1954)  1954   \n",
       "9      Slumber Party Massacre II (1987)  1987   \n",
       "\n",
       "                                              Script  \\\n",
       "0  DAMN, WHERE ARE WE?\\n WHEW, WE GOTTA FIND SOME...   \n",
       "1  1\\n [ Birds chirping in distance ]\\n [ Phone r...   \n",
       "2  Ah, James.\\n Ali Mahmud Jahar.\\n Remember him?...   \n",
       "3  On Christmas Day, 2016,\\n we heard with shock\\...   \n",
       "4  This is Burma...\\n the toughest battleground i...   \n",
       "5  MISS CLAYTON: Okay,\\n find a seat. Sit down, p...   \n",
       "6  Oh... boy...\\n That's a fast fish.\\n C'mon... ...   \n",
       "7  Don't mourn for Joe Strombel.\\n Joe Strombel l...   \n",
       "8  1\\n (dramatic music)\\n (flute music)\\n (singer...   \n",
       "9  Dr. Weiss says\\n that it's perfectly normal\\n ...   \n",
       "\n",
       "                                        Clean Script  \\\n",
       "0  [damn, where, are, we, whew, we, gotta, find, ...   \n",
       "1  [birds, chirping, in, distance, phone, ringing...   \n",
       "2  [ah, james, ali, mahmud, jahar, remember, him,...   \n",
       "3  [on, christmas, day, we, heard, with, shock, a...   \n",
       "4  [this, is, burma, the, toughest, battleground,...   \n",
       "5  [miss, clayton, okay, find, a, seat, sit, down...   \n",
       "6  [oh, boy, thats, a, fast, fish, cmon, cmon, cm...   \n",
       "7  [dont, mourn, for, joe, strombel, joe, strombe...   \n",
       "8  [dramatic, music, flute, music, singer, vocali...   \n",
       "9  [dr, weiss, says, that, its, perfectly, normal...   \n",
       "\n",
       "                                        Clean_Script  surprise   neutral  \\\n",
       "0  [damn, where, are, we, whew, we, gotta, find, ...  0.444444  0.066667   \n",
       "1  [birds, chirping, in, distance, phone, ringing...  0.227273  0.136364   \n",
       "2  [ah, james, ali, mahmud, jahar, remember, him,...       NaN  0.365854   \n",
       "3  [on, christmas, day, we, heard, with, shock, a...  0.142857  0.111111   \n",
       "4  [this, is, burma, the, toughest, battleground,...  0.059524  0.607143   \n",
       "5  [miss, clayton, okay, find, a, seat, sit, down...  0.158730  0.206349   \n",
       "6  [oh, boy, thats, a, fast, fish, cmon, cmon, cm...  0.500000  0.020000   \n",
       "7  [dont, mourn, for, joe, strombel, joe, strombe...  0.264463  0.173554   \n",
       "8  [dramatic, music, flute, music, singer, vocali...  0.150000  0.337500   \n",
       "9  [dr, weiss, says, that, its, perfectly, normal...  0.387755  0.020408   \n",
       "\n",
       "       fear     anger       joy  ...  sentiment_std  hapax  fkgl    fre  smog  \\\n",
       "0  0.133333  0.200000  0.022222  ...       0.722642    482   1.3  98.21   5.6   \n",
       "1  0.060606  0.060606  0.287879  ...       0.936315    453   2.9  88.63   6.7   \n",
       "2  0.414634       NaN       NaN  ...       0.741620    536   3.6  81.49   7.6   \n",
       "3  0.150794  0.047619  0.253968  ...       0.995992   1090   5.5  81.93   8.6   \n",
       "4  0.214286  0.023810  0.035714  ...       0.806599    801   2.4  89.85   6.2   \n",
       "5  0.142857  0.301587  0.079365  ...       0.782881    634   2.6  89.55   6.4   \n",
       "6  0.080000  0.160000  0.180000  ...       1.160577    564   2.2  90.36   5.9   \n",
       "7  0.280992  0.008264  0.165289  ...       0.908257   1047   2.7  89.14   7.1   \n",
       "8  0.287500  0.037500  0.137500  ...       0.746299    714   2.6  89.34   6.7   \n",
       "9  0.244898  0.020408  0.183673  ...       1.136515    457   2.2  95.98   5.8   \n",
       "\n",
       "    fog  word count       TTR  script_length  mean_word_length  \n",
       "0  3.31         949  0.203125           4672          3.858305  \n",
       "1  3.75         988  0.149245           6620          3.939275  \n",
       "2  4.41         952  0.235294           4046          4.260257  \n",
       "3  6.96        2043  0.151580          13478          4.016471  \n",
       "4  3.50        1579  0.182543           8650          3.998613  \n",
       "5  3.67        1251  0.196112           6379          3.994670  \n",
       "6  3.46        1041  0.203281           5121          3.932630  \n",
       "7  4.23        1935  0.153219          12629          3.991290  \n",
       "8  3.80        1405  0.175933           7986          4.086026  \n",
       "9  4.13         954  0.181853           5246          3.773351  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "embedder(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "035310e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06529bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (1) does not match length of index (10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClean_Script\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m [df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScript\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(clean_words)\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mSeries)]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/pandas/core/frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/pandas/core/frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4517\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4530\u001b[0m     ):\n\u001b[1;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/pandas/core/frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5266\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/pandas/core/common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (1) does not match length of index (10)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99502cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df786b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
