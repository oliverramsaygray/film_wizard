{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "241180aa",
   "metadata": {},
   "source": [
    "## Edited SVD- minus Fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44eb6df6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T09:59:11.477841Z",
     "start_time": "2025-03-18T09:59:10.908801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "print(\"Authenticated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "53a16182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:43:25.748550Z",
     "start_time": "2025-03-18T12:43:10.251979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded movie metadata: (87461, 4)\n",
      "Loaded data from BigQuery: (2000000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169430</td>\n",
       "      <td>25</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30484</td>\n",
       "      <td>136235</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89021</td>\n",
       "      <td>1584</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20980</td>\n",
       "      <td>4285</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7858</td>\n",
       "      <td>93126</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0  169430       25     2.5\n",
       "1   30484   136235     2.5\n",
       "2   89021     1584     5.0\n",
       "3   20980     4285     3.0\n",
       "4    7858    93126     1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from surprise.accuracy import rmse\n",
    "import pandas as pd\n",
    "\n",
    "# Define BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Define batch size & dataset properties\n",
    "BATCH_SIZE = 1_000_000  # 100k rows per batch\n",
    "TOTAL_ROWS = 32_000_000  # Approximate total dataset size\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "\n",
    "movie_metadata_query = \"\"\"\n",
    "SELECT movieId, title, imdbId, tmdbId\n",
    "FROM `film-wizard-453315.Grouplens.movies_with_imdb`\n",
    "\"\"\"\n",
    "\n",
    "# Fetch metadata from BigQuery\n",
    "movie_metadata_df = client.query(movie_metadata_query).to_dataframe()\n",
    "print(\"Loaded movie metadata:\", movie_metadata_df.shape)\n",
    "\n",
    "# Convert movie metadata into a dictionary for fast lookup\n",
    "movie_metadata = movie_metadata_df.set_index(\"movieId\")[[\"title\", \"imdbId\", \"tmdbId\"]]\n",
    "\n",
    "\n",
    "### **GL df**\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM `film-wizard-453315.Grouplens.raw_grouplens_ratings`\n",
    "ORDER BY RAND()\n",
    "LIMIT 2000000\n",
    "\"\"\"\n",
    "\n",
    "# Fetch data from BigQuery for Surprise 3 columns limit\n",
    "gl_df = client.query(sample_query).to_dataframe()\n",
    "print(\"Loaded data from BigQuery:\", gl_df.shape)\n",
    "display(gl_df.head(5))\n",
    "\n",
    "data = Dataset.load_from_df(gl_df, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "86e6891d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:43:30.656396Z",
     "start_time": "2025-03-18T12:43:29.737198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(155121, {'title': 'Kshanam', 'imdbId': 5504168, 'tmdbId': 386427}), (168730, {'title': 'Mumford & Sons: We Wrote This Yesterday', 'imdbId': 6268930, 'tmdbId': 439121}), (157787, {'title': '.hack Liminality: In the Case of Mai Minase', 'imdbId': 371501, 'tmdbId': 93734}), (183935, {'title': 'Made in Italy', 'imdbId': 6917242, 'tmdbId': 500268}), (213620, {'title': 'Playtime with Destiny', 'imdbId': 11898442, 'tmdbId': 680842})]\n",
      "[(155121, {'title': 'Kshanam', 'imdbId': 5504168, 'tmdbId': 386427}), (168730, {'title': 'Mumford & Sons: We Wrote This Yesterday', 'imdbId': 6268930, 'tmdbId': 439121}), (157787, {'title': '.hack Liminality: In the Case of Mai Minase', 'imdbId': 371501, 'tmdbId': 93734}), (183935, {'title': 'Made in Italy', 'imdbId': 6917242, 'tmdbId': 500268}), (213620, {'title': 'Playtime with Destiny', 'imdbId': 11898442, 'tmdbId': 680842})]\n"
     ]
    }
   ],
   "source": [
    "movie_metadata_df[\"movieId\"] = movie_metadata_df[\"movieId\"].astype(int)  # Ensure movieId is integer\n",
    "\n",
    "# Correctly convert to a dictionary\n",
    "movie_metadata = movie_metadata_df.set_index(\"movieId\")[[\"title\", \"imdbId\", \"tmdbId\"]].to_dict(orient=\"index\")\n",
    "\n",
    "# Check sample output\n",
    "print(list(movie_metadata.items())[:5])  # Should print first 5 movieId mappings\n",
    "\n",
    "print(list(movie_metadata.items())[:5])  # Print first 5 movieId-title pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f6841726",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:50:55.589885Z",
     "start_time": "2025-03-18T12:50:55.543869Z"
    }
   },
   "outputs": [],
   "source": [
    "#Accept new user input...via csv for now\n",
    "\n",
    "# gl_df['userId'].max()+1\n",
    "\n",
    "new_user_ratings = pd.read_csv('/Users/adamdyerson/Downloads/updated_ollie_ratings2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3f0b1ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:50:57.675022Z",
     "start_time": "2025-03-18T12:50:57.665494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Letterboxd URI</th>\n",
       "      <th>Rating</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09/05/2021</td>\n",
       "      <td>Three Billboards Outside Ebbing, Missouri</td>\n",
       "      <td>2017</td>\n",
       "      <td>https://boxd.it/ceBS</td>\n",
       "      <td>4.5</td>\n",
       "      <td>177593.0</td>\n",
       "      <td>200949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16/05/2021</td>\n",
       "      <td>Nomadland</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://boxd.it/lnRy</td>\n",
       "      <td>4.0</td>\n",
       "      <td>225145.0</td>\n",
       "      <td>200949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17/05/2021</td>\n",
       "      <td>Lady Bird</td>\n",
       "      <td>2017</td>\n",
       "      <td>https://boxd.it/dGNE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>177615.0</td>\n",
       "      <td>200949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03/07/2021</td>\n",
       "      <td>Yesterday</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://boxd.it/iF7M</td>\n",
       "      <td>2.5</td>\n",
       "      <td>201811.0</td>\n",
       "      <td>200949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03/07/2021</td>\n",
       "      <td>Coco</td>\n",
       "      <td>2017</td>\n",
       "      <td>https://boxd.it/bYJQ</td>\n",
       "      <td>3.5</td>\n",
       "      <td>177765.0</td>\n",
       "      <td>200949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>05/07/2021</td>\n",
       "      <td>mid90s</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://boxd.it/fxIa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>05/07/2021</td>\n",
       "      <td>The Street</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://boxd.it/ndKQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>263705.0</td>\n",
       "      <td>200949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21/07/2021</td>\n",
       "      <td>There Will Be Blood</td>\n",
       "      <td>2007</td>\n",
       "      <td>https://boxd.it/20Z2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>56782.0</td>\n",
       "      <td>200949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21/07/2021</td>\n",
       "      <td>Pain and Glory</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://boxd.it/iOBQ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>202237.0</td>\n",
       "      <td>200949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22/07/2021</td>\n",
       "      <td>Senna</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://boxd.it/kfE</td>\n",
       "      <td>3.5</td>\n",
       "      <td>85774.0</td>\n",
       "      <td>200949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28/12/2021</td>\n",
       "      <td>Fences</td>\n",
       "      <td>2016</td>\n",
       "      <td>https://boxd.it/dL6A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>166705.0</td>\n",
       "      <td>200949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28/12/2021</td>\n",
       "      <td>Don't Look Up</td>\n",
       "      <td>2021</td>\n",
       "      <td>https://boxd.it/o0Hc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>263407.0</td>\n",
       "      <td>200949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                       Name  Year  \\\n",
       "0   09/05/2021  Three Billboards Outside Ebbing, Missouri  2017   \n",
       "1   16/05/2021                                  Nomadland  2020   \n",
       "2   17/05/2021                                  Lady Bird  2017   \n",
       "3   03/07/2021                                  Yesterday  2019   \n",
       "4   03/07/2021                                       Coco  2017   \n",
       "5   05/07/2021                                     mid90s  2018   \n",
       "6   05/07/2021                                 The Street  2019   \n",
       "7   21/07/2021                        There Will Be Blood  2007   \n",
       "8   21/07/2021                             Pain and Glory  2019   \n",
       "9   22/07/2021                                      Senna  2010   \n",
       "10  28/12/2021                                     Fences  2016   \n",
       "11  28/12/2021                              Don't Look Up  2021   \n",
       "\n",
       "          Letterboxd URI  Rating   MovieID  userId  \n",
       "0   https://boxd.it/ceBS     4.5  177593.0  200949  \n",
       "1   https://boxd.it/lnRy     4.0  225145.0  200949  \n",
       "2   https://boxd.it/dGNE     3.0  177615.0  200949  \n",
       "3   https://boxd.it/iF7M     2.5  201811.0  200949  \n",
       "4   https://boxd.it/bYJQ     3.5  177765.0  200949  \n",
       "5   https://boxd.it/fxIa     4.0       NaN  200949  \n",
       "6   https://boxd.it/ndKQ     4.0  263705.0  200949  \n",
       "7   https://boxd.it/20Z2     3.5   56782.0  200949  \n",
       "8   https://boxd.it/iOBQ     3.0  202237.0  200949  \n",
       "9    https://boxd.it/kfE     3.5   85774.0  200949  \n",
       "10  https://boxd.it/dL6A     4.0  166705.0  200949  \n",
       "11  https://boxd.it/o0Hc     3.0  263407.0  200949  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign a User ID to the new input\n",
    "\n",
    "new_user_id = gl_df['userId'].max() + 1\n",
    "new_user_ratings['userId'] = new_user_id  # Assign new userId to all rows\n",
    "new_user_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "71ba19f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:51:14.997441Z",
     "start_time": "2025-03-18T12:51:01.404282Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Create the SVD model and train it\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "def get_top_n(predictions, n, movie_metadata):\n",
    "    \"\"\"Returns top N movie recommendations for each user with metadata.\"\"\"\n",
    "    top_n = {}\n",
    "\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid not in top_n:\n",
    "            top_n[uid] = []\n",
    "        \n",
    "        # Fetch movie details from metadata dictionary\n",
    "        movie_details = movie_metadata.get(iid, {\"title\": \"Unknown Title\", \"imdbId\": \"N/A\", \"tmdbId\": \"N/A\"})\n",
    "        \n",
    "        # Append movie details instead of just movieId\n",
    "        top_n[uid].append((movie_details[\"title\"], movie_details[\"imdbId\"], movie_details[\"tmdbId\"], round(est, 2)))\n",
    "\n",
    "    # Sort the predictions for each user and return the top n\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[3], reverse=True)  # Sort by predicted rating\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    \n",
    "    return top_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2bc1432c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:48:08.567684Z",
     "start_time": "2025-03-18T12:46:57.249837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9050  0.9044  0.9064  0.9038  0.9064  0.9052  0.0011  \n",
      "MAE (testset)     0.6931  0.6934  0.6943  0.6925  0.6944  0.6935  0.0007  \n",
      "Fit time          10.04   9.69    10.66   9.53    10.25   10.04   0.40    \n",
      "Test time         0.89    0.96    1.98    1.91    2.15    1.58    0.54    \n",
      "\n",
      "===== Cross-Validation Results =====\n",
      "Average Fit Time: 10.04 sec\n",
      "Average Test Time: 1.58 sec\n",
      "Average RMSE: 0.9052\n",
      "Average MAE: 0.6935\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_results = cross_validate(model, data, cv=5, verbose=True)\n",
    "\n",
    "# Compute average values for each metric\n",
    "avg_fit_time = sum(cv_results['fit_time']) / len(cv_results['fit_time'])\n",
    "avg_test_time = sum(cv_results['test_time']) / len(cv_results['test_time'])\n",
    "avg_rmse = sum(cv_results['test_rmse']) / len(cv_results['test_rmse'])\n",
    "avg_mae = sum(cv_results['test_mae']) / len(cv_results['test_mae'])\n",
    "\n",
    "# Display results\n",
    "print(\"\\n===== Cross-Validation Results =====\")\n",
    "print(f\"Average Fit Time: {avg_fit_time:.2f} sec\")\n",
    "print(f\"Average Test Time: {avg_test_time:.2f} sec\")\n",
    "print(f\"Average RMSE: {avg_rmse:.4f}\")\n",
    "print(f\"Average MAE: {avg_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f3ae2787",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:51:20.763886Z",
     "start_time": "2025-03-18T12:51:17.197780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Recommendations for User 11157:\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for the testset\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Get the top 10 recommendations for each user\n",
    "top_n = get_top_n(predictions, n=10, movie_metadata=movie_metadata)\n",
    "\n",
    "# Get recommendations for a specific user (example: user ID 11157)\n",
    "user_recommendations = top_n.get(11157, [])\n",
    "\n",
    "# Display recommendations\n",
    "print(f\"Top 10 Recommendations for User 11157:\")\n",
    "for title, imdb_id, tmdb_id, rating in user_recommendations:\n",
    "    print(f\"- {title} (IMDb: {imdb_id}, TMDb: {tmdb_id}) -> Predicted Rating: {rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf7d345a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:00:13.662018Z",
     "start_time": "2025-03-18T12:00:13.654903Z"
    }
   },
   "outputs": [],
   "source": [
    "# top_n.get(200949)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "80bbe6c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:32:19.483371Z",
     "start_time": "2025-03-18T12:32:19.476578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IntegerArray>\n",
       "[110975,   1517,   4734,   1639,   2248,   1282,  93326, 180297,   7899,\n",
       "   6870,\n",
       " ...\n",
       " 120789, 262879, 127220, 133255, 113080,   4818, 112741, 287229,  80812,\n",
       " 187283]\n",
       "Length: 27576, dtype: Int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gl_df.movieId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6e92e9b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:51:22.855307Z",
     "start_time": "2025-03-18T12:51:22.841604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.764545220263573"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(200949, gl_df.movieId.unique()[0])[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2e33b08a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:51:49.335563Z",
     "start_time": "2025-03-18T12:51:24.978030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        movieId    Rating                     Title\n",
      "0          25.0  3.764545         Leaving Las Vegas\n",
      "1      136235.0  3.364946           Hercules Reborn\n",
      "2        1584.0  3.714225                   Contact\n",
      "3        4285.0  3.447259        Frankie and Johnny\n",
      "4       93126.0  3.361751              Bag of Bones\n",
      "...         ...       ...                       ...\n",
      "36039  117320.0  3.540448             The Last Word\n",
      "36040  134763.0  3.522730             To Trap A Spy\n",
      "36041  206111.0  3.434485                Baby Steps\n",
      "36042   26314.0  3.523063  Cars That Ate Paris, The\n",
      "36043  111119.0  3.455658     Man in the Wilderness\n",
      "\n",
      "[36044 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "result = pd.DataFrame()\n",
    "for ind, i in enumerate(gl_df.movieId.unique()):\n",
    "    rating = model.predict(200949, i)[3]\n",
    "    result.loc[ind, 'movieId'] = int(i)\n",
    "    result.loc[ind, 'Rating'] = rating\n",
    "    # Lookup title from movie_metadata dictionary\n",
    "    result.loc[ind, 'Title'] = movie_metadata.get(i, {}).get(\"title\", \"Unknown\")\n",
    "# Display the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d5c77546",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T12:51:51.461563Z",
     "start_time": "2025-03-18T12:51:51.451926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>159817.0</td>\n",
       "      <td>4.540486</td>\n",
       "      <td>Planet Earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>171011.0</td>\n",
       "      <td>4.494497</td>\n",
       "      <td>Planet Earth II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>170705.0</td>\n",
       "      <td>4.466337</td>\n",
       "      <td>Band of Brothers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>46855.0</td>\n",
       "      <td>4.440160</td>\n",
       "      <td>Army of Shadows (L'armée des ombres)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12508</th>\n",
       "      <td>8684.0</td>\n",
       "      <td>4.422617</td>\n",
       "      <td>Man Escaped, A (Un  condamné à mort s'est écha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>318.0</td>\n",
       "      <td>4.420636</td>\n",
       "      <td>Shawshank Redemption, The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>142115.0</td>\n",
       "      <td>4.407571</td>\n",
       "      <td>The Blue Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>26082.0</td>\n",
       "      <td>4.379367</td>\n",
       "      <td>Harakiri (Seppuku)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>858.0</td>\n",
       "      <td>4.363542</td>\n",
       "      <td>Godfather, The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7375</th>\n",
       "      <td>7505.0</td>\n",
       "      <td>4.357391</td>\n",
       "      <td>Kingdom, The (Riget)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        movieId    Rating                                              Title\n",
       "5549   159817.0  4.540486                                       Planet Earth\n",
       "2756   171011.0  4.494497                                    Planet Earth II\n",
       "2150   170705.0  4.466337                                   Band of Brothers\n",
       "1614    46855.0  4.440160               Army of Shadows (L'armée des ombres)\n",
       "12508    8684.0  4.422617  Man Escaped, A (Un  condamné à mort s'est écha...\n",
       "41        318.0  4.420636                          Shawshank Redemption, The\n",
       "4457   142115.0  4.407571                                    The Blue Planet\n",
       "4402    26082.0  4.379367                                 Harakiri (Seppuku)\n",
       "154       858.0  4.363542                                     Godfather, The\n",
       "7375     7505.0  4.357391                               Kingdom, The (Riget)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values(by='Rating', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5054e7",
   "metadata": {},
   "source": [
    "# Fuzzy Logic Code if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Fuzzy matching ###\n",
    "# ### **GL df**\n",
    "# sample_query = \"\"\"\n",
    "# SELECT movieId, title\n",
    "# FROM `film-wizard-453315.Grouplens.grouplens_movies`\n",
    "# \"\"\"\n",
    "\n",
    "# # Fetch data from BigQuery\n",
    "# grouplens_movies = client.query(sample_query).to_dataframe()\n",
    "# print(\"Loaded data from BigQuery:\", gl_df.shape)\n",
    "# display(grouplens_movies.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef5b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fuzzywuzzy import fuzz, process\n",
    "# import pandas as pd\n",
    "\n",
    "# def fuzzy_match(df1, col1, df2, col2, threshold=80):\n",
    "#     matched_data = []\n",
    "#     choices = df2[col2].tolist()  # Convert column to a list to avoid unpacking issues\n",
    "\n",
    "#     for name in df1[col1]:\n",
    "#         result = process.extractOne(name, choices, scorer=fuzz.ratio)\n",
    "#         match, score = result if result else (\"\", 0)  # Ensure safe unpacking\n",
    "#         matched_data.append((name, match if score >= threshold else None, score))\n",
    "\n",
    "#     return pd.DataFrame(matched_data, columns=[col1, 'Matched_Title', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a1570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# matches_df = fuzzy_match(new_user_ratings, 'Name', grouplens_movies, 'title')\n",
    "# display(matches_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c134ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the data into a training and test set\n",
    "# trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# # Create the SVD model and train it\n",
    "# model = SVD()\n",
    "# model.fit(trainset)\n",
    "\n",
    "# # Define a function to get top 5 recommendations for a user\n",
    "# def get_top_n(predictions, n):\n",
    "#     top_n = {}\n",
    "#     for uid, iid, true_r, est, _ in predictions:\n",
    "#         if uid not in top_n:\n",
    "#             top_n[uid] = []\n",
    "#         top_n[uid].append((iid, round(est, 2)))\n",
    "\n",
    "#     # Sort the predictions for each user and return the top n\n",
    "#     for uid, user_ratings in top_n.items():\n",
    "#         user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "#         top_n[uid] = user_ratings[:n]\n",
    "    \n",
    "#     return top_n\n",
    "\n",
    "# # Load your data from BigQuery (assuming you have already loaded gl_df)\n",
    "# # Here's an example:\n",
    "# # gl_df = pd.read_csv('your_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b179c1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Lenskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f710a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from lenskit import crossfold\n",
    "from lenskit.als import BiasedMFScorer # https://lkpy.lenskit.org/stable/guide/gettingstarted\n",
    "from lenskit import util\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "print(\"Authenticated successfully!\")\n",
    "\n",
    "# Define batch size & dataset properties\n",
    "BATCH_SIZE = 100_000  # 100k rows per batch\n",
    "TOTAL_ROWS = 500_000  # Approximate total dataset size\n",
    "\n",
    "# Fetch 500k ratings from BigQuery randomly (for the entire dataset)\n",
    "sample_query = \"\"\"\n",
    "SELECT userId, movieId, rating\n",
    "FROM film-wizard-453315.Grouplens.500k_ratings\n",
    "ORDER BY RAND()\n",
    "\"\"\"\n",
    "sample_gl_df = client.query(sample_query).to_dataframe()\n",
    "\n",
    "# Rename columns to match LensKit's expected column names\n",
    "sample_gl_df = sample_gl_df.rename(columns={'userId': 'user_id', 'movieId': 'item_id'})\n",
    "sample_gl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf2491e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# I ned to define cv, hyperparam grid and then do a gridsearch\n",
    "\n",
    "# Train the model\n",
    "model = als.BiasedMF(features=3, reg=0.01, rng_spec=42)\n",
    "\n",
    "# Fit the model with your data\n",
    "model.fit(sample_gl_df[['user_id', 'item_id', 'rating']])\n",
    "\n",
    "# Create a scorer from the model\n",
    "scorer = model.scorer()\n",
    "\n",
    "# # ---------------------------\n",
    "\n",
    "# # Prepare data for training\n",
    "# train_data = sample_gl_df[['user', 'item', 'rating']]\n",
    "\n",
    "# # Define cross-validation with LensKit\n",
    "# folds = crossfold.sample_users(train_data, 5, size=0.2, method='random')  # 5-fold cross-validation\n",
    "\n",
    "# # Define a function for ALS model training\n",
    "# def train_als_model(train_data, factors=10, reg=0.01):\n",
    "#     algo = als.ALS(factors=factors, reg=reg, random_state=42)\n",
    "#     algo.fit(train_data)\n",
    "#     return algo\n",
    "\n",
    "# # Example hyperparameter grid (number of factors and regularization)\n",
    "# param_grid = {\n",
    "#     \"factors\": [5, 10, 50],\n",
    "#     \"reg\": [0.001, 0.01, 0.05]\n",
    "# }\n",
    "\n",
    "# # Manually grid search\n",
    "# best_rmse = float('inf')\n",
    "# best_params = {}\n",
    "\n",
    "# for factors in param_grid[\"factors\"]:\n",
    "#     for reg in param_grid[\"reg\"]:\n",
    "#         fold_rmse = []\n",
    "        \n",
    "#         for train, test in folds:\n",
    "#             model = train_als_model(train, factors=factors, reg=reg)\n",
    "            \n",
    "#             # Ensure the test data is in the form of a list of tuples (user, item)\n",
    "#             user_item_pairs = list(test[['user', 'item']].itertuples(index=False, name=None))\n",
    "            \n",
    "#             # Make predictions for these user-item pairs\n",
    "#             pred = model.predict(user_item_pairs)\n",
    "            \n",
    "#             # Calculate RMSE\n",
    "#             rmse_val = util.rmse(pred, test['rating'])\n",
    "#             fold_rmse.append(rmse_val)\n",
    "        \n",
    "#         mean_rmse = sum(fold_rmse) / len(fold_rmse)\n",
    "#         print(f\"Factors: {factors}, Reg: {reg}, RMSE: {mean_rmse}\")\n",
    "        \n",
    "#         if mean_rmse < best_rmse:\n",
    "#             best_rmse = mean_rmse\n",
    "#             best_params = {'factors': factors, 'reg': reg}\n",
    "\n",
    "# print(f\"Best Params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e5a0d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train the model using best hyperparameters from grid search\n",
    "best_algo = train_als_model(train_data, best_params['factors'], best_params['reg'])\n",
    "\n",
    "# Perform cross-validation to evaluate performance\n",
    "fold_rmse = []\n",
    "\n",
    "for train, test in folds:\n",
    "    model = train_als_model(train, best_params['factors'], best_params['reg'])\n",
    "    pred = model.predict(test[['userId', 'movieId']])\n",
    "    rmse_val = util.rmse(pred, test['rating'])\n",
    "    fold_rmse.append(rmse_val)\n",
    "\n",
    "print(f\"Cross-validation RMSE: {sum(fold_rmse)/len(fold_rmse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb542d63",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train on full dataset in batches\n",
    "for offset in range(0, TOTAL_ROWS, BATCH_SIZE):\n",
    "    batch_query = f\"\"\"\n",
    "    SELECT userId, movieId, rating\n",
    "    FROM film-wizard-453315.Grouplens.500k_ratings\n",
    "    ORDER BY userId\n",
    "    LIMIT {BATCH_SIZE} OFFSET {offset}\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_df = client.query(batch_query).to_dataframe()\n",
    "    \n",
    "    if batch_df.empty:\n",
    "        break  # Stop when there are no more rows\n",
    "    \n",
    "    train_data = batch_df[['userId', 'movieId', 'rating']]\n",
    "    \n",
    "    # Train the model on this batch\n",
    "    best_algo.fit(train_data)\n",
    "    print(f\"✅ Processed {offset + BATCH_SIZE} rows\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4286b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predict rating for a specific user and movie\n",
    "user_id = 10531\n",
    "movie_id = 100\n",
    "\n",
    "# Make prediction using the trained ALS model\n",
    "prediction = best_algo.predict(user_id, movie_id)\n",
    "print(f\"Predicted rating for user {user_id} and movie {movie_id}: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fffea9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Notes from original SVD jn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105bd81",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Path to your CSV file\n",
    "csv_path = \"/Users/oliverramsaygray/code/oliverramsaygray/film_wizard/raw_data/Adam films/9a884b4e-8993-4800-925a-bea11dcce39e.csv\"\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "movies_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Convert the 'date' column to datetime if it's not already\n",
    "movies_df['Date'] = pd.to_datetime(movies_df['Date'])\n",
    "\n",
    "# Filter out movies released in or after October 2023\n",
    "movies_df = movies_df[movies_df['Date'] < '2023-10-01']\n",
    "\n",
    "#Filter out movies that Grouplens later has an issue matching with\n",
    "# Exclude specific movies by title\n",
    "movies_to_exclude = [\"Herod's Law\", \"Spirited Away\", \"Sing\", \"Living\", \"Fury\"]  # Replace with actual movie titles\n",
    "movies_df = movies_df[~movies_df['Name'].isin(movies_to_exclude)]\n",
    "\n",
    "##### Half the ratings to be out of 5 - only for Adam #####\n",
    "movies_df['Rating'] = movies_df['Rating']/2\n",
    "\n",
    "# Sort by 'date' in descending order to get the most recent entries\n",
    "oliver_recent_movies = movies_df.sort_values(by='Date', ascending=False).head(10)\n",
    "\n",
    "# Show the most recent 10 movies and their ratings\n",
    "display(oliver_recent_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204bb3b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Set up BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Query to fetch the relevant data from BigQuery\n",
    "query = \"\"\"\n",
    "SELECT movieId, title\n",
    "FROM `film-wizard-453315.Grouplens.grouplens_movies`\n",
    "\"\"\"\n",
    "# Fetch data from BigQuery and load it into a DataFrame\n",
    "grouplens_movies_df = client.query(query).to_dataframe()\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "display('grouplens_movies_df:')\n",
    "display(grouplens_movies_df.head())\n",
    "\n",
    "# Perform fuzzy matching between 'title' in 'oliver_recent_movies' and 'title' in 'grouplens_movies_df'\n",
    "def get_best_match(title, choices, scorer=fuzz.ratio):\n",
    "    \"\"\"Fuzzy match using fuzz.ratio and return the best match.\"\"\"\n",
    "    match = process.extractOne(title, choices, scorer=scorer)\n",
    "    return match[0] if match else None\n",
    "\n",
    "# Apply fuzzy matching to the titles in 'oliver_recent_movies'\n",
    "oliver_recent_movies['matched_title'] = oliver_recent_movies['Name'].apply(\n",
    "    get_best_match, args=(grouplens_movies_df['title'],)\n",
    ")\n",
    "\n",
    "# Merge the original 'oliver_recent_movies' DataFrame with 'grouplens_movies_df' based on the 'matched_title'\n",
    "test_movies_with_ids = pd.merge(\n",
    "    oliver_recent_movies, \n",
    "    grouplens_movies_df[['title', 'movieId']], \n",
    "    left_on='matched_title', \n",
    "    right_on='title', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "##### Drop the 'matched_title' column and any other unnecessary columns - didn't use with Adam's csv\n",
    "# test_movies_with_ids = test_movies_with_ids.drop(columns=['matched_title', 'Letterboxd URI', 'title', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346fbc6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_movies_with_ids.drop_duplicates(inplace=True)\n",
    "\n",
    "# Show the final DataFrame\n",
    "display(test_movies_with_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c109099",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get all movie IDs in the GL dataset (this could be all movies in the system or a smaller list)\n",
    "all_movie_ids = full_gl_df['movieId'].unique()\n",
    "\n",
    "# Find unwatched movies for user 1 (exclude movies that user 1 has already rated)\n",
    "unwatched_movie_ids = [i for i in all_movie_ids if i not in test_movies_with_ids['movieId'].values]\n",
    "\n",
    "# Make predictions for the unwatched movies\n",
    "predictions = [best_algo.predict(1, movie_id) for movie_id in unwatched_movie_ids]\n",
    "\n",
    "# Sort the predictions by predicted rating (descending order)\n",
    "predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "# Extract top X recommended movies with their predicted ratings\n",
    "recommended_movies = [(pred.iid, pred.est) for pred in predictions[:10]]\n",
    "\n",
    "# Convert to DataFrame\n",
    "recommended_df = pd.DataFrame(recommended_movies, columns=[\"Movie ID\", \"Predicted Rating\"])\n",
    "display(recommended_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edde4d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display(recommended_df.info())\n",
    "display(grouplens_movies_df.info())\n",
    "\n",
    "# Bring back titles\n",
    "final_recommendation = pd.merge(\n",
    "    recommended_df, \n",
    "    grouplens_movies_df[['title', 'movieId']], \n",
    "    left_on='Movie ID', \n",
    "    right_on='movieId', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "final_recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af52cb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Understanding the Grouplens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa69832",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "\n",
    "# Pull table from bq\n",
    "sample_query = \"\"\"\n",
    "SELECT *\n",
    "FROM `film-wizard-453315.Grouplens.grouplens_movies`\n",
    "ORDER BY RAND()\n",
    "LIMIT 1000  -- Adjust for ~1% of 32M rows\n",
    "\"\"\"\n",
    "\n",
    "test_df = client.query(sample_query).to_dataframe()\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eb2ccc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('SVD_film_model.pkl', 'rb') as file:\n",
    "    best_algo_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adea233",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make predictions for the unwatched movies\n",
    "predictions = best_algo.predict(157707, 1)\n",
    "predictions\n",
    "\n",
    "# Sort the predictions by predicted rating (descending order)\n",
    "# predictions.sort(key=lambda x: x.est, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf7389",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69108055",
   "metadata": {},
   "source": [
    "## Online example of Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680fcc28",
   "metadata": {},
   "source": [
    "##### https://medium.com/@ckucewicz21/building-a-simple-movie-recommendation-system-with-surprise-6e61479e1e73"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
