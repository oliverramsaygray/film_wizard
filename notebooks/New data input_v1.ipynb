{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10d0f4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTasks\\n- Replace gl movieId with tmbd id\\n- Add new 2023-2025 movies in from Letterboxd with new uniqueIds and tmdb ids for movies\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Tasks\n",
    "- Replace gl movieId with tmbd id\n",
    "- Add new 2023-2025 movies in from Letterboxd with new uniqueIds and tmdb ids for movies\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89ff553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client(project=\"film-wizard-453315\")\n",
    "print(\"Authenticated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067bcb00",
   "metadata": {},
   "source": [
    "## Existing GL ratings plus tmdb ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ec57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverramsaygray/.pyenv/versions/3.10.6/envs/film_wizard/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1900: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch added: 1000000 rows (Offset: 0)\n",
      "Batch added: 1000000 rows (Offset: 1000000)\n",
      "Batch added: 1000000 rows (Offset: 2000000)\n"
     ]
    }
   ],
   "source": [
    "# Define batch size\n",
    "batch_size = 1_000_000  # Adjust as needed\n",
    "offset = 0\n",
    "all_data = []\n",
    "\n",
    "while True:\n",
    "    # Define query with LIMIT and OFFSET\n",
    "    sample_query = f\"\"\"\n",
    "    SELECT userId, movieId, rating\n",
    "    FROM `film-wizard-453315.Grouplens.raw_grouplens_ratings`\n",
    "    LIMIT {batch_size} OFFSET {offset}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fetch batch\n",
    "    batch_df = client.query(sample_query).to_dataframe()\n",
    "    \n",
    "    # Break loop if no more data\n",
    "    if batch_df.empty:\n",
    "        print(\"No more data to fetch. Stopping batch process.\")\n",
    "        break\n",
    "    \n",
    "    # Append to list\n",
    "    all_data.append(batch_df)\n",
    "    \n",
    "    # Confirm batch retrieval\n",
    "    print(f\"Batch added: {len(batch_df)} rows (Offset: {offset})\")\n",
    "    \n",
    "    # Move offset\n",
    "    offset += batch_size\n",
    "\n",
    "# Concatenate all batches into final DataFrame\n",
    "gl_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Display final result\n",
    "gl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce6298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch links table\n",
    "sample_query = \"\"\"\n",
    "SELECT *\n",
    "FROM `film-wizard-453315.Grouplens.raw_grouplens_links`\n",
    "\"\"\"\n",
    "links_df = client.query(sample_query).to_dataframe()\n",
    "links_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5efd699",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_gl_tmdb_df = pd.merge(gl_df, links_df, on='movieId', how='inner') #163 rows don't have tmdb ids so are dropped if using 'inner'. This is 28 unique movies.\n",
    "initial_gl_tmdb_df = initial_gl_tmdb_df[[\"userId\", \"movieId\", \"tmdbId\", \"rating\"]]\n",
    "initial_gl_tmdb_df\n",
    "\n",
    "## To check how many unique gl movieIds are being lost with left vs inner join\n",
    "# nan_movie_ids_count = initial_gl_tmdb_df[initial_gl_tmdb_df['tmdbId'].isna()]['movieId'].nunique()\n",
    "# nan_movie_ids_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24b2847",
   "metadata": {},
   "source": [
    "## Letterboxd ratings plus tmdb ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8511f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Letterboxd reviews\n",
    "sample_query = \"\"\"\n",
    "SELECT *\n",
    "FROM `film-wizard-453315.Letterboxd.letterboxed_user_reviews`\n",
    "\"\"\"\n",
    "letterboxd_df = client.query(sample_query).to_dataframe()\n",
    "letterboxd_df['rating_val'] = letterboxd_df['rating_val']/2\n",
    "letterboxd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7660893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch tmdb data\n",
    "sample_query = \"\"\"\n",
    "SELECT tmdbId, title, release_date\n",
    "FROM `film-wizard-453315.tmdb_metadata.all_movies_combined`\n",
    "\"\"\"\n",
    "tmdb_df = client.query(sample_query).to_dataframe()\n",
    "\n",
    "print('')\n",
    "\n",
    "tmdb_df['release_date'] = pd.to_datetime(tmdb_df['release_date'])\n",
    "\n",
    "# 1) Get the data types of each column\n",
    "print(\"Data types of each column:\")\n",
    "print(tmdb_df.dtypes)\n",
    "\n",
    "print('')\n",
    "\n",
    "# 2) Count the non-NaN values\n",
    "release_date_count = tmdb_df['title'].count()\n",
    "print(\"Non-NaN values in title column:\", release_date_count)\n",
    "\n",
    "release_date_count = tmdb_df['release_date'].count()\n",
    "print(\"Non-NaN values in release_date column:\", release_date_count)\n",
    "\n",
    "tmdb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0cfd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to clean movie titles for better fuzzy matching\n",
    "def clean_title(title):\n",
    "    \"\"\"\n",
    "    Cleans a movie title by:\n",
    "    - Converting to lowercase\n",
    "    - Replacing hyphens with spaces\n",
    "    - Removing all characters except letters, numbers, and spaces\n",
    "    \"\"\"\n",
    "    if not isinstance(title, str):  # Handle None values\n",
    "        return \"\"\n",
    "    title = title.lower()\n",
    "    title = title.replace(\" - \", \" \")  # Normalize spaces around hyphens\n",
    "    title = title.replace(\"-\", \" \")    # Convert remaining hyphens to spaces\n",
    "    title = re.sub(r'[^a-z0-9 ]', '', title)  # Remove punctuation\n",
    "    return title.strip()\n",
    "\n",
    "# Function to extract the release year from the title\n",
    "def extract_year(title):\n",
    "    \"\"\"\n",
    "    Extracts a 4-digit year from a movie title, if present.\n",
    "    Returns the year as an integer or None if no year is found.\n",
    "    \"\"\"\n",
    "    if not isinstance(title, str):  # Handle None values\n",
    "        return None\n",
    "    match = re.search(r'\\b(19|20)\\d{2}\\b', title)  # Look for years between 1900-2099\n",
    "    return int(match.group()) if match else None\n",
    "\n",
    "# Apply preprocessing to clean movie titles\n",
    "letterboxd_df['clean_movie_id'] = letterboxd_df['movie_id'].apply(clean_title)\n",
    "tmdb_df['clean_title'] = tmdb_df['title'].apply(clean_title)\n",
    "\n",
    "# Extract years from both dataframes\n",
    "letterboxd_df['year'] = letterboxd_df['movie_id'].apply(extract_year)\n",
    "tmdb_df['year'] = tmdb_df['title'].apply(extract_year)\n",
    "\n",
    "# Convert TMDB titles into a list for faster lookup\n",
    "tmdb_titles = tmdb_df['clean_title'].tolist()\n",
    "\n",
    "# Lists to store match results\n",
    "matched_titles = []\n",
    "fuzzy_scores = []\n",
    "matched_tmdb_ids = []\n",
    "\n",
    "# Perform fuzzy matching for each movie in the Letterboxd dataset\n",
    "for index, row in letterboxd_df.iterrows():\n",
    "    movie_id = row['clean_movie_id']\n",
    "    movie_year = row['year']  # Extract year for additional filtering\n",
    "\n",
    "    if not movie_id:  # Skip empty movie IDs\n",
    "        matched_titles.append(None)\n",
    "        fuzzy_scores.append(None)\n",
    "        matched_tmdb_ids.append(None)\n",
    "        continue\n",
    "\n",
    "    # Get top 5 matches using a strict ratio-based scoring system\n",
    "    matches = process.extract(movie_id, tmdb_titles, scorer=fuzz.ratio, limit=5)\n",
    "\n",
    "    # Filter to only matches that score above 90 (strong match)\n",
    "    valid_matches = [match for match in matches if match[1] >= 90]\n",
    "\n",
    "    # If a release year is available, prefer matches with the same year\n",
    "    if movie_year:\n",
    "        year_matched_df = tmdb_df[\n",
    "            (tmdb_df['clean_title'].isin([match[0] for match in valid_matches])) & \n",
    "            (tmdb_df['year'] == movie_year)\n",
    "        ]\n",
    "        if not year_matched_df.empty:\n",
    "            best_match = (year_matched_df.iloc[0]['clean_title'], 100)  # Assign perfect score\n",
    "        else:\n",
    "            best_match = valid_matches[0] if valid_matches else matches[0]\n",
    "    else:\n",
    "        best_match = valid_matches[0] if valid_matches else matches[0]\n",
    "\n",
    "    # Retrieve the original TMDB title and ID\n",
    "    match_row = tmdb_df.loc[tmdb_df['clean_title'] == best_match[0]]\n",
    "    matched_titles.append(match_row['title'].values[0] if not match_row.empty else None)\n",
    "    fuzzy_scores.append(best_match[1])\n",
    "    matched_tmdb_ids.append(match_row['tmdbId'].values[0] if not match_row.empty else None)\n",
    "\n",
    "# Add match results to DataFrame\n",
    "letterboxd_df['matched_title'] = matched_titles\n",
    "letterboxd_df['fuzzy_score'] = fuzzy_scores\n",
    "letterboxd_df['matched_tmdbId'] = matched_tmdb_ids  # Add tmdbId to final DataFrame\n",
    "\n",
    "# Display the first 50 results\n",
    "letterboxd_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "letterboxd_df = letterboxd_df[['user_id', 'matched_tmdbId', 'rating_val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21ee099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Get the maximum existing userId from gl_df\n",
    "max_user_id = gl_df['userId'].max()\n",
    "\n",
    "# Create a mapping of unique user_id values to new sequential numbers\n",
    "unique_users = letterboxd_df['user_id'].unique()\n",
    "user_id_mapping = {user: idx for idx, user in enumerate(unique_users, start=max_user_id + 1)}\n",
    "\n",
    "# Apply the mapping to the user_id column\n",
    "letterboxd_df['new_user_id'] = letterboxd_df['user_id'].map(user_id_mapping)\n",
    "\n",
    "# Display the updated dataframe\n",
    "letterboxd_df = letterboxd_df[['new_user_id', 'matched_tmdbId', 'rating_val']]\n",
    "letterboxd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992fa388",
   "metadata": {},
   "outputs": [],
   "source": [
    "letterboxd_df = letterboxd_df.rename(columns={'new_user_id': 'userId', \n",
    "                                      'matched_tmdbId': 'movieId', \n",
    "                                      'rating_val': 'rating'})\n",
    "master_df = pd.concat([gl_df, letterboxd_df], ignore_index=True)\n",
    "master_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
